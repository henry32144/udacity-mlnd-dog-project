{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Concatenate, GlobalMaxPooling2D, Average\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Permute, multiply\n",
    "#from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmenter(train=True):\n",
    "    # from https://github.com/aleju/imgaug\n",
    "    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image\n",
    "    # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "    # in 50% of all cases. In all other cases they will sample new values\n",
    "    # _per channel_.\n",
    "    if train:\n",
    "        seq = iaa.Sequential(\n",
    "            [\n",
    "                # apply the following augmenters to most images\n",
    "                iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "                iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "                # crop images by -5% to 10% of their height/width\n",
    "                sometimes(iaa.CropAndPad(\n",
    "                    percent=(-0.05, 0.1),\n",
    "                    pad_mode=ia.ALL, # random mode from all available modes will be sampled per image.\n",
    "                    pad_cval=(0, 255) # The constant value to use if the pad mode is constant or the end value to use if the mode is linear_ramp\n",
    "                )),\n",
    "                sometimes(iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                    shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "                    cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                    mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                )),\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        pass\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/mpalermo/keras-pipeline-custom-generator-imgaug\n",
    "class BaseDataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images_paths, labels, batch_size=64, image_dimensions = (512, 512, 3),\n",
    "                 shuffle=False, augmenter=None, preprocessor=None,\n",
    "                 return_label=True, total_classes=None):\n",
    "        self.labels       = labels              # array of labels\n",
    "        self.images_paths = images_paths        # array of image paths\n",
    "        self.dim          = image_dimensions    # image dimensions\n",
    "        self.batch_size   = batch_size          # batch size\n",
    "        self.shuffle      = shuffle             # shuffle bool\n",
    "        self.augmenter      = augmenter           # augmenter\n",
    "        self.preprocessor = preprocessor\n",
    "        self.return_label = return_label\n",
    "        self.total_classes = total_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def gather_batch_item(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # selects indices of data for next batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # select data and load images\n",
    "        images = [cv2.imread(self.images_paths[k]) for k in indexes]\n",
    "\n",
    "        # preprocess and augment data\n",
    "        if self.augmenter:\n",
    "            images = self.augmenter.augment_images(images)\n",
    "\n",
    "        images= np.array([self.preprocess_image(cv2.resize(img, self.dim[:2])) for img in images])\n",
    "        \n",
    "        if self.return_label:\n",
    "            labels = np.array([self.labels[k] for k in indexes])\n",
    "            labels = to_categorical(labels, num_classes=self.total_classes)\n",
    "            return images, labels\n",
    "        else:\n",
    "            return images\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.gather_batch_item(index)\n",
    "        \n",
    "    def preprocess_image(self, images):\n",
    "        if self.preprocessor is None:\n",
    "            images = images / 255.\n",
    "            pass\n",
    "        else:\n",
    "            images = self.preprocessor(images)\n",
    "        return images\n",
    "    \n",
    "class MultiOutputDataGenerator(BaseDataGenerator):\n",
    "    'Generates multiple output data for Keras'\n",
    "    def __init__(self, images_paths, labels, batch_size=64, image_dimensions = (512, 512, 3),\n",
    "                 shuffle=False, augmenter=None, preprocessor=None,\n",
    "                 return_label=True, total_classes=None, output_names=None, tta_augmentors=None):\n",
    "        # Init parent's parameter\n",
    "        super().__init__(images_paths,\n",
    "                labels, batch_size, image_dimensions,\n",
    "                 shuffle, augmenter, preprocessor,\n",
    "                 return_label, total_classes)\n",
    "        \n",
    "        self.output_names = output_names\n",
    "        self.tta_augmentors = tta_augmentors\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.return_label:\n",
    "            images, labels = self.gather_batch_item(index)\n",
    "            output_dict = {}\n",
    "            # Copy labels to each output name\n",
    "            for output_name in self.output_names:\n",
    "                output_dict[output_name] = labels\n",
    "            if self.tta_augmentors != None:\n",
    "                images = self.get_tta_images(images)\n",
    "            return images, output_dict\n",
    "        else:\n",
    "            images = self.gather_batch_item(index)\n",
    "            if self.tta_augmentors != None:\n",
    "                images = self.get_tta_images(images)\n",
    "            return images\n",
    "    def get_tta_images(self, images):\n",
    "        aug_images = []\n",
    "        # Original\n",
    "        aug_images.append(images)\n",
    "        for augmentor in self.tta_augmentors:\n",
    "            aug_images.append(augmentor.augment_images(images))\n",
    "        images = aug_images\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain model input size\n",
    "image_shape = (224, 224, 3)\n",
    "\n",
    "# 133\n",
    "total_classes = len(os.listdir('dogImages/train')) \n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_labels(path):\n",
    "    all_classes = os.listdir(path)\n",
    "    label_dict = {}\n",
    "    img_paths, label_list = [], []\n",
    "    for label_name in all_classes:\n",
    "        label_num, dog_name = label_name.split('.')\n",
    "        # Start with 0\n",
    "        label_num = int(label_num) - 1\n",
    "        label_dict[int(label_num)] = dog_name\n",
    "        for image_name in os.listdir(path + '/' + label_name):\n",
    "            img_paths.append(path + '/' + label_name + '/' + image_name)\n",
    "            label_list.append(label_num)\n",
    "    df = pd.DataFrame({'img_path': img_paths, 'label': label_list})\n",
    "    return label_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_label_dict, df_train = create_path_labels('dogImages/train')\n",
    "_, df_val = create_path_labels('dogImages/valid')\n",
    "_, df_test = create_path_labels('dogImages/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Affenpinscher',\n",
       " 1: 'Afghan_hound',\n",
       " 2: 'Airedale_terrier',\n",
       " 3: 'Akita',\n",
       " 4: 'Alaskan_malamute',\n",
       " 5: 'American_eskimo_dog',\n",
       " 6: 'American_foxhound',\n",
       " 7: 'American_staffordshire_terrier',\n",
       " 8: 'American_water_spaniel',\n",
       " 9: 'Anatolian_shepherd_dog',\n",
       " 10: 'Australian_cattle_dog',\n",
       " 11: 'Australian_shepherd',\n",
       " 12: 'Australian_terrier',\n",
       " 13: 'Basenji',\n",
       " 14: 'Basset_hound',\n",
       " 15: 'Beagle',\n",
       " 16: 'Bearded_collie',\n",
       " 17: 'Beauceron',\n",
       " 18: 'Bedlington_terrier',\n",
       " 19: 'Belgian_malinois',\n",
       " 20: 'Belgian_sheepdog',\n",
       " 21: 'Belgian_tervuren',\n",
       " 22: 'Bernese_mountain_dog',\n",
       " 23: 'Bichon_frise',\n",
       " 24: 'Black_and_tan_coonhound',\n",
       " 25: 'Black_russian_terrier',\n",
       " 26: 'Bloodhound',\n",
       " 27: 'Bluetick_coonhound',\n",
       " 28: 'Border_collie',\n",
       " 29: 'Border_terrier',\n",
       " 30: 'Borzoi',\n",
       " 31: 'Boston_terrier',\n",
       " 32: 'Bouvier_des_flandres',\n",
       " 33: 'Boxer',\n",
       " 34: 'Boykin_spaniel',\n",
       " 35: 'Briard',\n",
       " 36: 'Brittany',\n",
       " 37: 'Brussels_griffon',\n",
       " 38: 'Bull_terrier',\n",
       " 39: 'Bulldog',\n",
       " 40: 'Bullmastiff',\n",
       " 41: 'Cairn_terrier',\n",
       " 42: 'Canaan_dog',\n",
       " 43: 'Cane_corso',\n",
       " 44: 'Cardigan_welsh_corgi',\n",
       " 45: 'Cavalier_king_charles_spaniel',\n",
       " 46: 'Chesapeake_bay_retriever',\n",
       " 47: 'Chihuahua',\n",
       " 48: 'Chinese_crested',\n",
       " 49: 'Chinese_shar-pei',\n",
       " 50: 'Chow_chow',\n",
       " 51: 'Clumber_spaniel',\n",
       " 52: 'Cocker_spaniel',\n",
       " 53: 'Collie',\n",
       " 54: 'Curly-coated_retriever',\n",
       " 55: 'Dachshund',\n",
       " 56: 'Dalmatian',\n",
       " 57: 'Dandie_dinmont_terrier',\n",
       " 58: 'Doberman_pinscher',\n",
       " 59: 'Dogue_de_bordeaux',\n",
       " 60: 'English_cocker_spaniel',\n",
       " 61: 'English_setter',\n",
       " 62: 'English_springer_spaniel',\n",
       " 63: 'English_toy_spaniel',\n",
       " 64: 'Entlebucher_mountain_dog',\n",
       " 65: 'Field_spaniel',\n",
       " 66: 'Finnish_spitz',\n",
       " 67: 'Flat-coated_retriever',\n",
       " 68: 'French_bulldog',\n",
       " 69: 'German_pinscher',\n",
       " 70: 'German_shepherd_dog',\n",
       " 71: 'German_shorthaired_pointer',\n",
       " 72: 'German_wirehaired_pointer',\n",
       " 73: 'Giant_schnauzer',\n",
       " 74: 'Glen_of_imaal_terrier',\n",
       " 75: 'Golden_retriever',\n",
       " 76: 'Gordon_setter',\n",
       " 77: 'Great_dane',\n",
       " 78: 'Great_pyrenees',\n",
       " 79: 'Greater_swiss_mountain_dog',\n",
       " 80: 'Greyhound',\n",
       " 81: 'Havanese',\n",
       " 82: 'Ibizan_hound',\n",
       " 83: 'Icelandic_sheepdog',\n",
       " 84: 'Irish_red_and_white_setter',\n",
       " 85: 'Irish_setter',\n",
       " 86: 'Irish_terrier',\n",
       " 87: 'Irish_water_spaniel',\n",
       " 88: 'Irish_wolfhound',\n",
       " 89: 'Italian_greyhound',\n",
       " 90: 'Japanese_chin',\n",
       " 91: 'Keeshond',\n",
       " 92: 'Kerry_blue_terrier',\n",
       " 93: 'Komondor',\n",
       " 94: 'Kuvasz',\n",
       " 95: 'Labrador_retriever',\n",
       " 96: 'Lakeland_terrier',\n",
       " 97: 'Leonberger',\n",
       " 98: 'Lhasa_apso',\n",
       " 99: 'Lowchen',\n",
       " 100: 'Maltese',\n",
       " 101: 'Manchester_terrier',\n",
       " 102: 'Mastiff',\n",
       " 103: 'Miniature_schnauzer',\n",
       " 104: 'Neapolitan_mastiff',\n",
       " 105: 'Newfoundland',\n",
       " 106: 'Norfolk_terrier',\n",
       " 107: 'Norwegian_buhund',\n",
       " 108: 'Norwegian_elkhound',\n",
       " 109: 'Norwegian_lundehund',\n",
       " 110: 'Norwich_terrier',\n",
       " 111: 'Nova_scotia_duck_tolling_retriever',\n",
       " 112: 'Old_english_sheepdog',\n",
       " 113: 'Otterhound',\n",
       " 114: 'Papillon',\n",
       " 115: 'Parson_russell_terrier',\n",
       " 116: 'Pekingese',\n",
       " 117: 'Pembroke_welsh_corgi',\n",
       " 118: 'Petit_basset_griffon_vendeen',\n",
       " 119: 'Pharaoh_hound',\n",
       " 120: 'Plott',\n",
       " 121: 'Pointer',\n",
       " 122: 'Pomeranian',\n",
       " 123: 'Poodle',\n",
       " 124: 'Portuguese_water_dog',\n",
       " 125: 'Saint_bernard',\n",
       " 126: 'Silky_terrier',\n",
       " 127: 'Smooth_fox_terrier',\n",
       " 128: 'Tibetan_mastiff',\n",
       " 129: 'Welsh_springer_spaniel',\n",
       " 130: 'Wirehaired_pointing_griffon',\n",
       " 131: 'Xoloitzcuintli',\n",
       " 132: 'Yorkshire_terrier'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label\n",
       "0  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "1  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "2  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "3  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "4  dogImages/train/001.Affenpinscher/Affenpinsche...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 2)\n",
      "(835, 2)\n",
      "(836, 2)\n"
     ]
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = MultiOutputDataGenerator(images_paths=df_train['img_path'].values, labels=df_train['label'].values,\n",
    "                              batch_size=batch_size, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=create_augmenter(train=True), preprocessor=preprocess_input,\n",
    "                             return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "val_datagen = MultiOutputDataGenerator(images_paths=df_val['img_path'].values, labels=df_val['label'].values,\n",
    "                              batch_size=5, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                                return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=1, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "167\n",
      "836\n"
     ]
    }
   ],
   "source": [
    "print(len(train_datagen))\n",
    "print(len(val_datagen))\n",
    "print(len(test_datagen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squeeze_excite_block(tensor, ratio=16):\n",
    "    # From: https://github.com/titu1994/keras-squeeze-excite-network\n",
    "    init = tensor\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = K.int_shape(init)[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling = None - output shape (None, 8, 8, 1536)\n",
    "# pooling = max  - output shape (None, 1536)\n",
    "# pooling = avg  - output shape (None, 1536)\n",
    "\n",
    "pretrained = MobileNetV2(include_top=False, weights='imagenet', input_shape=image_shape, pooling=None)\n",
    "x = pretrained.output\n",
    "\n",
    "# Original branch\n",
    "gavg = GlobalAveragePooling2D()(x)\n",
    "gmax = GlobalMaxPooling2D()(x)\n",
    "original_concat = Concatenate(axis=-1)([gavg, gmax,])\n",
    "original_concat = Dropout(0.5)(original_concat)\n",
    "original_final = Dense(total_classes, activation='softmax', name='original_out')(original_concat)\n",
    "\n",
    "# SE branch\n",
    "se_out = squeeze_excite_block(x)\n",
    "se_gavg = GlobalAveragePooling2D()(se_out)\n",
    "se_gmax = GlobalMaxPooling2D()(se_out)\n",
    "se_concat = Concatenate(axis=-1)([se_gavg, se_gmax,])\n",
    "se_concat = Dropout(0.5)(se_concat)\n",
    "se_final = Dense(total_classes, activation='softmax', name='se_out')(se_concat)\n",
    "\n",
    "model = Model(inputs=pretrained.input, outputs=[original_final, se_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 1280)   0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 80)     102400      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 1280)   102400      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 7, 7, 1280)   0           out_relu[0][0]                   \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 1280)         0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 1280)         0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2560)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2560)         0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2560)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2560)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "original_out (Dense)            (None, 133)          340613      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "se_out (Dense)                  (None, 133)          340613      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,144,010\n",
      "Trainable params: 3,109,898\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.MobileNetV2_warmup.hdf5', \n",
    "                                  verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "logdir = f\".\\logs\\warmup\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "    \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                               mode=\"min\",\n",
    "                               patience=15,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Maybe useful, haven't tried\n",
    "def scheduler(epoch):\n",
    "    if epoch < 50:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.MobileNetV2_best.hdf5', \n",
    "                                  verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 17.8618 - original_out_loss: 12.8082 - se_out_loss: 5.0536 - original_out_accuracy: 0.0697 - se_out_accuracy: 0.1327 \n",
      "Epoch 00001: val_loss improved from inf to 11.71253, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 117s 350ms/step - loss: 17.8541 - original_out_loss: 12.8046 - se_out_loss: 5.0494 - original_out_accuracy: 0.0701 - se_out_accuracy: 0.1331 - val_loss: 11.7125 - val_original_out_loss: 9.9487 - val_se_out_loss: 1.7639 - val_original_out_accuracy: 0.2491 - val_se_out_accuracy: 0.4958\n",
      "Epoch 2/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 14.1318 - original_out_loss: 11.3698 - se_out_loss: 2.7620 - original_out_accuracy: 0.1521 - se_out_accuracy: 0.3123  ETA: 56s - loss: 14.4802 - original_out_loss: 11.5544 \n",
      "Epoch 00002: val_loss improved from 11.71253 to 10.24856, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 114s 342ms/step - loss: 14.1243 - original_out_loss: 11.3634 - se_out_loss: 2.7608 - original_out_accuracy: 0.1522 - se_out_accuracy: 0.3121 - val_loss: 10.2486 - val_original_out_loss: 8.9087 - val_se_out_loss: 1.3399 - val_original_out_accuracy: 0.3257 - val_se_out_accuracy: 0.5940\n",
      "Epoch 3/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 12.9165 - original_out_loss: 10.5859 - se_out_loss: 2.3306 - original_out_accuracy: 0.2060 - se_out_accuracy: 0.3908\n",
      "Epoch 00003: val_loss improved from 10.24856 to 9.67974, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 114s 342ms/step - loss: 12.9138 - original_out_loss: 10.5843 - se_out_loss: 2.3295 - original_out_accuracy: 0.2061 - se_out_accuracy: 0.3912 - val_loss: 9.6797 - val_original_out_loss: 8.4933 - val_se_out_loss: 1.1864 - val_original_out_accuracy: 0.3689 - val_se_out_accuracy: 0.6443\n",
      "Epoch 4/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 12.5818 - original_out_loss: 10.4532 - se_out_loss: 2.1286 - original_out_accuracy: 0.2230 - se_out_accuracy: 0.4294\n",
      "Epoch 00004: val_loss improved from 9.67974 to 9.47499, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 113s 339ms/step - loss: 12.5813 - original_out_loss: 10.4532 - se_out_loss: 2.1281 - original_out_accuracy: 0.2231 - se_out_accuracy: 0.4295 - val_loss: 9.4750 - val_original_out_loss: 8.4180 - val_se_out_loss: 1.0570 - val_original_out_accuracy: 0.3725 - val_se_out_accuracy: 0.6731\n",
      "Epoch 5/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 12.2654 - original_out_loss: 10.2610 - se_out_loss: 2.0045 - original_out_accuracy: 0.2428 - se_out_accuracy: 0.4623\n",
      "Epoch 00005: val_loss improved from 9.47499 to 9.23153, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 116s 346ms/step - loss: 12.2678 - original_out_loss: 10.2629 - se_out_loss: 2.0049 - original_out_accuracy: 0.2428 - se_out_accuracy: 0.4621 - val_loss: 9.2315 - val_original_out_loss: 8.1844 - val_se_out_loss: 1.0471 - val_original_out_accuracy: 0.4072 - val_se_out_accuracy: 0.6838\n",
      "Epoch 6/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 12.0028 - original_out_loss: 10.1117 - se_out_loss: 1.8911 - original_out_accuracy: 0.2581 - se_out_accuracy: 0.4799\n",
      "Epoch 00006: val_loss improved from 9.23153 to 9.11306, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 116s 347ms/step - loss: 11.9975 - original_out_loss: 10.1087 - se_out_loss: 1.8888 - original_out_accuracy: 0.2581 - se_out_accuracy: 0.4802 - val_loss: 9.1131 - val_original_out_loss: 8.0853 - val_se_out_loss: 1.0277 - val_original_out_accuracy: 0.4132 - val_se_out_accuracy: 0.6826\n",
      "Epoch 7/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 11.8790 - original_out_loss: 10.0683 - se_out_loss: 1.8106 - original_out_accuracy: 0.2652 - se_out_accuracy: 0.5012\n",
      "Epoch 00007: val_loss did not improve from 9.11306\n",
      "334/334 [==============================] - 119s 355ms/step - loss: 11.8777 - original_out_loss: 10.0665 - se_out_loss: 1.8111 - original_out_accuracy: 0.2650 - se_out_accuracy: 0.5009 - val_loss: 9.2243 - val_original_out_loss: 8.2195 - val_se_out_loss: 1.0047 - val_original_out_accuracy: 0.3928 - val_se_out_accuracy: 0.6790\n",
      "Epoch 8/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 11.9270 - original_out_loss: 10.1288 - se_out_loss: 1.7982 - original_out_accuracy: 0.2682 - se_out_accuracy: 0.5074\n",
      "Epoch 00008: val_loss did not improve from 9.11306\n",
      "334/334 [==============================] - 116s 348ms/step - loss: 11.9286 - original_out_loss: 10.1290 - se_out_loss: 1.7996 - original_out_accuracy: 0.2683 - se_out_accuracy: 0.5072 - val_loss: 9.4669 - val_original_out_loss: 8.3903 - val_se_out_loss: 1.0766 - val_original_out_accuracy: 0.4048 - val_se_out_accuracy: 0.6802\n",
      "Epoch 9/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 11.7496 - original_out_loss: 10.0413 - se_out_loss: 1.7083 - original_out_accuracy: 0.2793 - se_out_accuracy: 0.5240\n",
      "Epoch 00009: val_loss did not improve from 9.11306\n",
      "334/334 [==============================] - 117s 349ms/step - loss: 11.7439 - original_out_loss: 10.0361 - se_out_loss: 1.7077 - original_out_accuracy: 0.2796 - se_out_accuracy: 0.5240 - val_loss: 9.3236 - val_original_out_loss: 8.2932 - val_se_out_loss: 1.0303 - val_original_out_accuracy: 0.4144 - val_se_out_accuracy: 0.6982\n",
      "Epoch 10/10\n",
      "333/334 [============================>.] - ETA: 0s - loss: 11.6172 - original_out_loss: 9.9419 - se_out_loss: 1.6753 - original_out_accuracy: 0.2883 - se_out_accuracy: 0.5353\n",
      "Epoch 00010: val_loss improved from 9.11306 to 9.07621, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 116s 347ms/step - loss: 11.6096 - original_out_loss: 9.9342 - se_out_loss: 1.6754 - original_out_accuracy: 0.2889 - se_out_accuracy: 0.5356 - val_loss: 9.0762 - val_original_out_loss: 8.0681 - val_se_out_loss: 1.0081 - val_original_out_accuracy: 0.4383 - val_se_out_accuracy: 0.7030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=10,\n",
    "                                       callbacks=[tensorboard_callback, early_stop, checkpointer],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = True\n",
    "\n",
    "logdir = f\".\\logs\\whole\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "sgd = SGD(lr=0.0005, momentum=0.0, decay=0.0, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 10.4090 - original_out_loss: 8.9538 - se_out_loss: 1.4552 - original_out_accuracy: 0.3541 - se_out_accuracy: 0.5913\n",
      "Epoch 00001: val_loss improved from 9.07621 to 8.76601, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 125s 373ms/step - loss: 10.4062 - original_out_loss: 8.9502 - se_out_loss: 1.4559 - original_out_accuracy: 0.3545 - se_out_accuracy: 0.5913 - val_loss: 8.7660 - val_original_out_loss: 7.7782 - val_se_out_loss: 0.9878 - val_original_out_accuracy: 0.4455 - val_se_out_accuracy: 0.7066\n",
      "Epoch 2/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 9.7059 - original_out_loss: 8.4100 - se_out_loss: 1.2959 - original_out_accuracy: 0.3877 - se_out_accuracy: 0.6230\n",
      "Epoch 00002: val_loss improved from 8.76601 to 8.62456, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 124s 371ms/step - loss: 9.7206 - original_out_loss: 8.4211 - se_out_loss: 1.2995 - original_out_accuracy: 0.3870 - se_out_accuracy: 0.6223 - val_loss: 8.6246 - val_original_out_loss: 7.6722 - val_se_out_loss: 0.9524 - val_original_out_accuracy: 0.4491 - val_se_out_accuracy: 0.7138\n",
      "Epoch 3/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 9.3722 - original_out_loss: 8.1722 - se_out_loss: 1.2001 - original_out_accuracy: 0.3968 - se_out_accuracy: 0.6417\n",
      "Epoch 00003: val_loss improved from 8.62456 to 8.42505, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 122s 366ms/step - loss: 9.3819 - original_out_loss: 8.1821 - se_out_loss: 1.1998 - original_out_accuracy: 0.3961 - se_out_accuracy: 0.6416 - val_loss: 8.4250 - val_original_out_loss: 7.5225 - val_se_out_loss: 0.9025 - val_original_out_accuracy: 0.4671 - val_se_out_accuracy: 0.7305\n",
      "Epoch 4/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 9.0714 - original_out_loss: 7.9383 - se_out_loss: 1.1330 - original_out_accuracy: 0.4114 - se_out_accuracy: 0.6602\n",
      "Epoch 00004: val_loss improved from 8.42505 to 8.29076, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 122s 364ms/step - loss: 9.0826 - original_out_loss: 7.9482 - se_out_loss: 1.1344 - original_out_accuracy: 0.4111 - se_out_accuracy: 0.6599 - val_loss: 8.2908 - val_original_out_loss: 7.4242 - val_se_out_loss: 0.8665 - val_original_out_accuracy: 0.4695 - val_se_out_accuracy: 0.7377\n",
      "Epoch 5/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.8808 - original_out_loss: 7.8168 - se_out_loss: 1.0640 - original_out_accuracy: 0.4305 - se_out_accuracy: 0.6727\n",
      "Epoch 00005: val_loss did not improve from 8.29076\n",
      "334/334 [==============================] - 125s 373ms/step - loss: 8.8792 - original_out_loss: 7.8151 - se_out_loss: 1.0641 - original_out_accuracy: 0.4307 - se_out_accuracy: 0.6728 - val_loss: 8.3452 - val_original_out_loss: 7.4495 - val_se_out_loss: 0.8957 - val_original_out_accuracy: 0.4707 - val_se_out_accuracy: 0.7210\n",
      "Epoch 6/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.7167 - original_out_loss: 7.6794 - se_out_loss: 1.0373 - original_out_accuracy: 0.4443 - se_out_accuracy: 0.6868\n",
      "Epoch 00006: val_loss improved from 8.29076 to 8.26852, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 121s 363ms/step - loss: 8.7182 - original_out_loss: 7.6809 - se_out_loss: 1.0374 - original_out_accuracy: 0.4442 - se_out_accuracy: 0.6867 - val_loss: 8.2685 - val_original_out_loss: 7.4308 - val_se_out_loss: 0.8377 - val_original_out_accuracy: 0.4766 - val_se_out_accuracy: 0.7413\n",
      "Epoch 7/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.5908 - original_out_loss: 7.5958 - se_out_loss: 0.9950 - original_out_accuracy: 0.4498 - se_out_accuracy: 0.7036\n",
      "Epoch 00007: val_loss improved from 8.26852 to 8.13001, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 127s 381ms/step - loss: 8.5786 - original_out_loss: 7.5830 - se_out_loss: 0.9956 - original_out_accuracy: 0.4506 - se_out_accuracy: 0.7031 - val_loss: 8.1300 - val_original_out_loss: 7.3007 - val_se_out_loss: 0.8293 - val_original_out_accuracy: 0.4862 - val_se_out_accuracy: 0.7521\n",
      "Epoch 8/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.4768 - original_out_loss: 7.5242 - se_out_loss: 0.9527 - original_out_accuracy: 0.4559 - se_out_accuracy: 0.7102\n",
      "Epoch 00008: val_loss improved from 8.13001 to 8.02668, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 127s 380ms/step - loss: 8.4798 - original_out_loss: 7.5276 - se_out_loss: 0.9522 - original_out_accuracy: 0.4557 - se_out_accuracy: 0.7105 - val_loss: 8.0267 - val_original_out_loss: 7.2536 - val_se_out_loss: 0.7731 - val_original_out_accuracy: 0.4922 - val_se_out_accuracy: 0.7581\n",
      "Epoch 9/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.4174 - original_out_loss: 7.4773 - se_out_loss: 0.9401 - original_out_accuracy: 0.4575 - se_out_accuracy: 0.7107\n",
      "Epoch 00009: val_loss improved from 8.02668 to 7.97455, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 124s 372ms/step - loss: 8.4136 - original_out_loss: 7.4746 - se_out_loss: 0.9389 - original_out_accuracy: 0.4578 - se_out_accuracy: 0.7112 - val_loss: 7.9745 - val_original_out_loss: 7.2316 - val_se_out_loss: 0.7429 - val_original_out_accuracy: 0.5006 - val_se_out_accuracy: 0.7593\n",
      "Epoch 10/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.2476 - original_out_loss: 7.3655 - se_out_loss: 0.8821 - original_out_accuracy: 0.4703 - se_out_accuracy: 0.7207\n",
      "Epoch 00010: val_loss improved from 7.97455 to 7.97223, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 124s 370ms/step - loss: 8.2474 - original_out_loss: 7.3654 - se_out_loss: 0.8819 - original_out_accuracy: 0.4702 - se_out_accuracy: 0.7208 - val_loss: 7.9722 - val_original_out_loss: 7.2503 - val_se_out_loss: 0.7219 - val_original_out_accuracy: 0.4922 - val_se_out_accuracy: 0.7784\n",
      "Epoch 11/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.1669 - original_out_loss: 7.2953 - se_out_loss: 0.8716 - original_out_accuracy: 0.4754 - se_out_accuracy: 0.7348\n",
      "Epoch 00011: val_loss improved from 7.97223 to 7.88245, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 127s 379ms/step - loss: 8.1721 - original_out_loss: 7.3002 - se_out_loss: 0.8718 - original_out_accuracy: 0.4751 - se_out_accuracy: 0.7346 - val_loss: 7.8825 - val_original_out_loss: 7.1679 - val_se_out_loss: 0.7146 - val_original_out_accuracy: 0.5006 - val_se_out_accuracy: 0.7832\n",
      "Epoch 12/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 8.1080 - original_out_loss: 7.2476 - se_out_loss: 0.8604 - original_out_accuracy: 0.4802 - se_out_accuracy: 0.7399\n",
      "Epoch 00012: val_loss improved from 7.88245 to 7.80955, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 124s 370ms/step - loss: 8.1038 - original_out_loss: 7.2425 - se_out_loss: 0.8614 - original_out_accuracy: 0.4804 - se_out_accuracy: 0.7395 - val_loss: 7.8095 - val_original_out_loss: 7.1346 - val_se_out_loss: 0.6750 - val_original_out_accuracy: 0.5030 - val_se_out_accuracy: 0.7880\n",
      "Epoch 13/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.9715 - original_out_loss: 7.1404 - se_out_loss: 0.8311 - original_out_accuracy: 0.4820 - se_out_accuracy: 0.7471\n",
      "Epoch 00013: val_loss improved from 7.80955 to 7.78421, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 111s 333ms/step - loss: 7.9688 - original_out_loss: 7.1377 - se_out_loss: 0.8311 - original_out_accuracy: 0.4820 - se_out_accuracy: 0.7470 - val_loss: 7.7842 - val_original_out_loss: 7.0914 - val_se_out_loss: 0.6928 - val_original_out_accuracy: 0.5042 - val_se_out_accuracy: 0.7808\n",
      "Epoch 14/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.9036 - original_out_loss: 7.0845 - se_out_loss: 0.8191 - original_out_accuracy: 0.4925 - se_out_accuracy: 0.7479\n",
      "Epoch 00014: val_loss improved from 7.78421 to 7.71061, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 121s 363ms/step - loss: 7.9111 - original_out_loss: 7.0917 - se_out_loss: 0.8193 - original_out_accuracy: 0.4921 - se_out_accuracy: 0.7478 - val_loss: 7.7106 - val_original_out_loss: 7.0275 - val_se_out_loss: 0.6831 - val_original_out_accuracy: 0.5090 - val_se_out_accuracy: 0.7820\n",
      "Epoch 15/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.8154 - original_out_loss: 7.0261 - se_out_loss: 0.7893 - original_out_accuracy: 0.4943 - se_out_accuracy: 0.7623\n",
      "Epoch 00015: val_loss did not improve from 7.71061\n",
      "334/334 [==============================] - 112s 334ms/step - loss: 7.8160 - original_out_loss: 7.0278 - se_out_loss: 0.7882 - original_out_accuracy: 0.4943 - se_out_accuracy: 0.7627 - val_loss: 7.7227 - val_original_out_loss: 7.0398 - val_se_out_loss: 0.6829 - val_original_out_accuracy: 0.5126 - val_se_out_accuracy: 0.7892\n",
      "Epoch 16/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.7868 - original_out_loss: 7.0146 - se_out_loss: 0.7722 - original_out_accuracy: 0.4979 - se_out_accuracy: 0.7665\n",
      "Epoch 00016: val_loss improved from 7.71061 to 7.67306, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 113s 337ms/step - loss: 7.7848 - original_out_loss: 7.0136 - se_out_loss: 0.7712 - original_out_accuracy: 0.4979 - se_out_accuracy: 0.7671 - val_loss: 7.6731 - val_original_out_loss: 7.0165 - val_se_out_loss: 0.6566 - val_original_out_accuracy: 0.5042 - val_se_out_accuracy: 0.7952\n",
      "Epoch 17/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.7317 - original_out_loss: 6.9648 - se_out_loss: 0.7669 - original_out_accuracy: 0.5038 - se_out_accuracy: 0.7610\n",
      "Epoch 00017: val_loss improved from 7.67306 to 7.63945, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 112s 334ms/step - loss: 7.7312 - original_out_loss: 6.9635 - se_out_loss: 0.7677 - original_out_accuracy: 0.5036 - se_out_accuracy: 0.7608 - val_loss: 7.6394 - val_original_out_loss: 6.9862 - val_se_out_loss: 0.6533 - val_original_out_accuracy: 0.5138 - val_se_out_accuracy: 0.7892\n",
      "Epoch 18/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.6390 - original_out_loss: 6.9032 - se_out_loss: 0.7357 - original_out_accuracy: 0.5123 - se_out_accuracy: 0.7694\n",
      "Epoch 00018: val_loss improved from 7.63945 to 7.60006, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 110s 329ms/step - loss: 7.6410 - original_out_loss: 6.9055 - se_out_loss: 0.7355 - original_out_accuracy: 0.5120 - se_out_accuracy: 0.7693 - val_loss: 7.6001 - val_original_out_loss: 6.9516 - val_se_out_loss: 0.6485 - val_original_out_accuracy: 0.5114 - val_se_out_accuracy: 0.7940\n",
      "Epoch 19/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.6514 - original_out_loss: 6.9044 - se_out_loss: 0.7470 - original_out_accuracy: 0.5105 - se_out_accuracy: 0.7701\n",
      "Epoch 00019: val_loss did not improve from 7.60006\n",
      "334/334 [==============================] - 110s 331ms/step - loss: 7.6474 - original_out_loss: 6.9012 - se_out_loss: 0.7462 - original_out_accuracy: 0.5108 - se_out_accuracy: 0.7704 - val_loss: 7.6323 - val_original_out_loss: 6.9867 - val_se_out_loss: 0.6456 - val_original_out_accuracy: 0.5150 - val_se_out_accuracy: 0.8036\n",
      "Epoch 20/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.5600 - original_out_loss: 6.8714 - se_out_loss: 0.6886 - original_out_accuracy: 0.5153 - se_out_accuracy: 0.7934\n",
      "Epoch 00020: val_loss improved from 7.60006 to 7.59990, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 110s 329ms/step - loss: 7.5608 - original_out_loss: 6.8727 - se_out_loss: 0.6881 - original_out_accuracy: 0.5153 - se_out_accuracy: 0.7936 - val_loss: 7.5999 - val_original_out_loss: 6.9565 - val_se_out_loss: 0.6434 - val_original_out_accuracy: 0.5138 - val_se_out_accuracy: 0.7964\n",
      "Epoch 21/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.5513 - original_out_loss: 6.8595 - se_out_loss: 0.6917 - original_out_accuracy: 0.5183 - se_out_accuracy: 0.7841\n",
      "Epoch 00021: val_loss improved from 7.59990 to 7.57145, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 115s 343ms/step - loss: 7.5520 - original_out_loss: 6.8598 - se_out_loss: 0.6922 - original_out_accuracy: 0.5183 - se_out_accuracy: 0.7841 - val_loss: 7.5715 - val_original_out_loss: 6.9599 - val_se_out_loss: 0.6116 - val_original_out_accuracy: 0.5150 - val_se_out_accuracy: 0.8168\n",
      "Epoch 22/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.5029 - original_out_loss: 6.8334 - se_out_loss: 0.6695 - original_out_accuracy: 0.5204 - se_out_accuracy: 0.7925\n",
      "Epoch 00022: val_loss improved from 7.57145 to 7.53574, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 113s 339ms/step - loss: 7.4951 - original_out_loss: 6.8264 - se_out_loss: 0.6687 - original_out_accuracy: 0.5208 - se_out_accuracy: 0.7927 - val_loss: 7.5357 - val_original_out_loss: 6.9246 - val_se_out_loss: 0.6111 - val_original_out_accuracy: 0.5162 - val_se_out_accuracy: 0.8180\n",
      "Epoch 23/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.4752 - original_out_loss: 6.8216 - se_out_loss: 0.6536 - original_out_accuracy: 0.5225 - se_out_accuracy: 0.7994\n",
      "Epoch 00023: val_loss improved from 7.53574 to 7.49324, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 114s 341ms/step - loss: 7.4804 - original_out_loss: 6.8261 - se_out_loss: 0.6543 - original_out_accuracy: 0.5222 - se_out_accuracy: 0.7988 - val_loss: 7.4932 - val_original_out_loss: 6.8918 - val_se_out_loss: 0.6015 - val_original_out_accuracy: 0.5234 - val_se_out_accuracy: 0.8240\n",
      "Epoch 24/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.4207 - original_out_loss: 6.7904 - se_out_loss: 0.6303 - original_out_accuracy: 0.5290 - se_out_accuracy: 0.8032\n",
      "Epoch 00024: val_loss did not improve from 7.49324\n",
      "334/334 [==============================] - 109s 326ms/step - loss: 7.4139 - original_out_loss: 6.7846 - se_out_loss: 0.6294 - original_out_accuracy: 0.5295 - se_out_accuracy: 0.8036 - val_loss: 7.5141 - val_original_out_loss: 6.9099 - val_se_out_loss: 0.6042 - val_original_out_accuracy: 0.5269 - val_se_out_accuracy: 0.8036\n",
      "Epoch 25/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.4311 - original_out_loss: 6.8002 - se_out_loss: 0.6309 - original_out_accuracy: 0.5263 - se_out_accuracy: 0.7952\n",
      "Epoch 00025: val_loss did not improve from 7.49324\n",
      "334/334 [==============================] - 113s 339ms/step - loss: 7.4281 - original_out_loss: 6.7964 - se_out_loss: 0.6317 - original_out_accuracy: 0.5263 - se_out_accuracy: 0.7948 - val_loss: 7.5181 - val_original_out_loss: 6.9113 - val_se_out_loss: 0.6068 - val_original_out_accuracy: 0.5246 - val_se_out_accuracy: 0.8120\n",
      "Epoch 26/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.4133 - original_out_loss: 6.8036 - se_out_loss: 0.6097 - original_out_accuracy: 0.5264 - se_out_accuracy: 0.8048\n",
      "Epoch 00026: val_loss did not improve from 7.49324\n",
      "334/334 [==============================] - 112s 335ms/step - loss: 7.4082 - original_out_loss: 6.7988 - se_out_loss: 0.6094 - original_out_accuracy: 0.5265 - se_out_accuracy: 0.8049 - val_loss: 7.5149 - val_original_out_loss: 6.9215 - val_se_out_loss: 0.5934 - val_original_out_accuracy: 0.5246 - val_se_out_accuracy: 0.8072\n",
      "Epoch 27/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.3812 - original_out_loss: 6.7689 - se_out_loss: 0.6123 - original_out_accuracy: 0.5302 - se_out_accuracy: 0.8107\n",
      "Epoch 00027: val_loss improved from 7.49324 to 7.46280, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 111s 332ms/step - loss: 7.3886 - original_out_loss: 6.7746 - se_out_loss: 0.6140 - original_out_accuracy: 0.5299 - se_out_accuracy: 0.8100 - val_loss: 7.4628 - val_original_out_loss: 6.8667 - val_se_out_loss: 0.5961 - val_original_out_accuracy: 0.5293 - val_se_out_accuracy: 0.8048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.3018 - original_out_loss: 6.7237 - se_out_loss: 0.5781 - original_out_accuracy: 0.5357 - se_out_accuracy: 0.8183\n",
      "Epoch 00028: val_loss did not improve from 7.46280\n",
      "334/334 [==============================] - 112s 335ms/step - loss: 7.3025 - original_out_loss: 6.7253 - se_out_loss: 0.5772 - original_out_accuracy: 0.5358 - se_out_accuracy: 0.8187 - val_loss: 7.4990 - val_original_out_loss: 6.8950 - val_se_out_loss: 0.6040 - val_original_out_accuracy: 0.5234 - val_se_out_accuracy: 0.8084\n",
      "Epoch 29/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.3262 - original_out_loss: 6.7400 - se_out_loss: 0.5862 - original_out_accuracy: 0.5324 - se_out_accuracy: 0.8134\n",
      "Epoch 00029: val_loss did not improve from 7.46280\n",
      "334/334 [==============================] - 110s 329ms/step - loss: 7.3289 - original_out_loss: 6.7428 - se_out_loss: 0.5861 - original_out_accuracy: 0.5322 - se_out_accuracy: 0.8135 - val_loss: 7.4880 - val_original_out_loss: 6.8964 - val_se_out_loss: 0.5916 - val_original_out_accuracy: 0.5305 - val_se_out_accuracy: 0.8156\n",
      "Epoch 30/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.3492 - original_out_loss: 6.7625 - se_out_loss: 0.5867 - original_out_accuracy: 0.5345 - se_out_accuracy: 0.8161\n",
      "Epoch 00030: val_loss did not improve from 7.46280\n",
      "334/334 [==============================] - 113s 338ms/step - loss: 7.3425 - original_out_loss: 6.7563 - se_out_loss: 0.5863 - original_out_accuracy: 0.5349 - se_out_accuracy: 0.8165 - val_loss: 7.4705 - val_original_out_loss: 6.8946 - val_se_out_loss: 0.5759 - val_original_out_accuracy: 0.5269 - val_se_out_accuracy: 0.8311\n",
      "Epoch 31/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.2370 - original_out_loss: 6.6702 - se_out_loss: 0.5667 - original_out_accuracy: 0.5428 - se_out_accuracy: 0.8186\n",
      "Epoch 00031: val_loss improved from 7.46280 to 7.44869, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 108s 323ms/step - loss: 7.2446 - original_out_loss: 6.6771 - se_out_loss: 0.5675 - original_out_accuracy: 0.5422 - se_out_accuracy: 0.8186 - val_loss: 7.4487 - val_original_out_loss: 6.8680 - val_se_out_loss: 0.5807 - val_original_out_accuracy: 0.5257 - val_se_out_accuracy: 0.8156\n",
      "Epoch 32/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.2189 - original_out_loss: 6.6486 - se_out_loss: 0.5703 - original_out_accuracy: 0.5417 - se_out_accuracy: 0.8168\n",
      "Epoch 00032: val_loss did not improve from 7.44869\n",
      "334/334 [==============================] - 114s 340ms/step - loss: 7.2205 - original_out_loss: 6.6486 - se_out_loss: 0.5719 - original_out_accuracy: 0.5418 - se_out_accuracy: 0.8165 - val_loss: 7.4886 - val_original_out_loss: 6.8967 - val_se_out_loss: 0.5919 - val_original_out_accuracy: 0.5210 - val_se_out_accuracy: 0.8048\n",
      "Epoch 33/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.1726 - original_out_loss: 6.6135 - se_out_loss: 0.5591 - original_out_accuracy: 0.5434 - se_out_accuracy: 0.8227\n",
      "Epoch 00033: val_loss improved from 7.44869 to 7.43466, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 110s 330ms/step - loss: 7.1659 - original_out_loss: 6.6080 - se_out_loss: 0.5579 - original_out_accuracy: 0.5434 - se_out_accuracy: 0.8231 - val_loss: 7.4347 - val_original_out_loss: 6.8422 - val_se_out_loss: 0.5924 - val_original_out_accuracy: 0.5246 - val_se_out_accuracy: 0.8036\n",
      "Epoch 34/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.1190 - original_out_loss: 6.5522 - se_out_loss: 0.5668 - original_out_accuracy: 0.5435 - se_out_accuracy: 0.8168\n",
      "Epoch 00034: val_loss improved from 7.43466 to 7.32158, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 112s 336ms/step - loss: 7.1210 - original_out_loss: 6.5534 - se_out_loss: 0.5676 - original_out_accuracy: 0.5434 - se_out_accuracy: 0.8166 - val_loss: 7.3216 - val_original_out_loss: 6.7446 - val_se_out_loss: 0.5770 - val_original_out_accuracy: 0.5257 - val_se_out_accuracy: 0.8036\n",
      "Epoch 35/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.0103 - original_out_loss: 6.4282 - se_out_loss: 0.5822 - original_out_accuracy: 0.5450 - se_out_accuracy: 0.8204\n",
      "Epoch 00035: val_loss improved from 7.32158 to 7.23247, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 116s 347ms/step - loss: 7.0151 - original_out_loss: 6.4327 - se_out_loss: 0.5824 - original_out_accuracy: 0.5449 - se_out_accuracy: 0.8204 - val_loss: 7.2325 - val_original_out_loss: 6.6342 - val_se_out_loss: 0.5982 - val_original_out_accuracy: 0.5186 - val_se_out_accuracy: 0.8036\n",
      "Epoch 36/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 6.8145 - original_out_loss: 6.2535 - se_out_loss: 0.5610 - original_out_accuracy: 0.5538 - se_out_accuracy: 0.8333\n",
      "Epoch 00036: val_loss improved from 7.23247 to 7.02379, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 113s 338ms/step - loss: 6.8140 - original_out_loss: 6.2531 - se_out_loss: 0.5609 - original_out_accuracy: 0.5537 - se_out_accuracy: 0.8334 - val_loss: 7.0238 - val_original_out_loss: 6.4286 - val_se_out_loss: 0.5952 - val_original_out_accuracy: 0.5305 - val_se_out_accuracy: 0.8180\n",
      "Epoch 37/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 6.6481 - original_out_loss: 6.0548 - se_out_loss: 0.5933 - original_out_accuracy: 0.5563 - se_out_accuracy: 0.8185\n",
      "Epoch 00037: val_loss improved from 7.02379 to 6.86949, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 109s 326ms/step - loss: 6.6532 - original_out_loss: 6.0608 - se_out_loss: 0.5924 - original_out_accuracy: 0.5560 - se_out_accuracy: 0.8187 - val_loss: 6.8695 - val_original_out_loss: 6.2475 - val_se_out_loss: 0.6220 - val_original_out_accuracy: 0.5437 - val_se_out_accuracy: 0.8036\n",
      "Epoch 38/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 6.3542 - original_out_loss: 5.6737 - se_out_loss: 0.6804 - original_out_accuracy: 0.5562 - se_out_accuracy: 0.8065\n",
      "Epoch 00038: val_loss improved from 6.86949 to 6.51446, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 119s 357ms/step - loss: 6.3520 - original_out_loss: 5.6718 - se_out_loss: 0.6802 - original_out_accuracy: 0.5561 - se_out_accuracy: 0.8066 - val_loss: 6.5145 - val_original_out_loss: 5.9031 - val_se_out_loss: 0.6114 - val_original_out_accuracy: 0.5449 - val_se_out_accuracy: 0.8036\n",
      "Epoch 39/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 5.2787 - original_out_loss: 4.0778 - se_out_loss: 1.2009 - original_out_accuracy: 0.5269 - se_out_accuracy: 0.7194\n",
      "Epoch 00039: val_loss improved from 6.51446 to 5.84723, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 110s 330ms/step - loss: 5.2728 - original_out_loss: 4.0713 - se_out_loss: 1.2014 - original_out_accuracy: 0.5272 - se_out_accuracy: 0.7193 - val_loss: 5.8472 - val_original_out_loss: 5.2014 - val_se_out_loss: 0.6459 - val_original_out_accuracy: 0.5521 - val_se_out_accuracy: 0.7964\n",
      "Epoch 40/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.0681 - original_out_loss: 2.7823 - se_out_loss: 1.2858 - original_out_accuracy: 0.5257 - se_out_accuracy: 0.7092\n",
      "Epoch 00040: val_loss improved from 5.84723 to 4.46079, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 111s 331ms/step - loss: 4.0676 - original_out_loss: 2.7813 - se_out_loss: 1.2863 - original_out_accuracy: 0.5257 - se_out_accuracy: 0.7091 - val_loss: 4.4608 - val_original_out_loss: 3.7743 - val_se_out_loss: 0.6865 - val_original_out_accuracy: 0.5629 - val_se_out_accuracy: 0.7940\n",
      "Epoch 41/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 3.2768 - original_out_loss: 2.2108 - se_out_loss: 1.0661 - original_out_accuracy: 0.5560 - se_out_accuracy: 0.7402\n",
      "Epoch 00041: val_loss improved from 4.46079 to 3.14027, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 116s 346ms/step - loss: 3.2783 - original_out_loss: 2.2122 - se_out_loss: 1.0661 - original_out_accuracy: 0.5560 - se_out_accuracy: 0.7404 - val_loss: 3.1403 - val_original_out_loss: 2.4248 - val_se_out_loss: 0.7155 - val_original_out_accuracy: 0.5832 - val_se_out_accuracy: 0.7844\n",
      "Epoch 42/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.7648 - original_out_loss: 1.8250 - se_out_loss: 0.9398 - original_out_accuracy: 0.5874 - se_out_accuracy: 0.7529\n",
      "Epoch 00042: val_loss improved from 3.14027 to 2.33389, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 121s 364ms/step - loss: 2.7617 - original_out_loss: 1.8228 - se_out_loss: 0.9388 - original_out_accuracy: 0.5877 - se_out_accuracy: 0.7533 - val_loss: 2.3339 - val_original_out_loss: 1.6228 - val_se_out_loss: 0.7111 - val_original_out_accuracy: 0.6479 - val_se_out_accuracy: 0.7832\n",
      "Epoch 43/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.3508 - original_out_loss: 1.5220 - se_out_loss: 0.8287 - original_out_accuracy: 0.6333 - se_out_accuracy: 0.7733\n",
      "Epoch 00043: val_loss improved from 2.33389 to 1.89585, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 123s 367ms/step - loss: 2.3491 - original_out_loss: 1.5208 - se_out_loss: 0.8284 - original_out_accuracy: 0.6337 - se_out_accuracy: 0.7734 - val_loss: 1.8959 - val_original_out_loss: 1.2086 - val_se_out_loss: 0.6873 - val_original_out_accuracy: 0.6934 - val_se_out_accuracy: 0.7940\n",
      "Epoch 44/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.1094 - original_out_loss: 1.3425 - se_out_loss: 0.7669 - original_out_accuracy: 0.6566 - se_out_accuracy: 0.7860\n",
      "Epoch 00044: val_loss improved from 1.89585 to 1.67922, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 120s 358ms/step - loss: 2.1096 - original_out_loss: 1.3425 - se_out_loss: 0.7671 - original_out_accuracy: 0.6570 - se_out_accuracy: 0.7859 - val_loss: 1.6792 - val_original_out_loss: 1.0061 - val_se_out_loss: 0.6731 - val_original_out_accuracy: 0.7389 - val_se_out_accuracy: 0.7964\n",
      "Epoch 45/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.9367 - original_out_loss: 1.2270 - se_out_loss: 0.7097 - original_out_accuracy: 0.6808 - se_out_accuracy: 0.7968\n",
      "Epoch 00045: val_loss improved from 1.67922 to 1.56803, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 121s 363ms/step - loss: 1.9362 - original_out_loss: 1.2262 - se_out_loss: 0.7100 - original_out_accuracy: 0.6808 - se_out_accuracy: 0.7967 - val_loss: 1.5680 - val_original_out_loss: 0.9242 - val_se_out_loss: 0.6439 - val_original_out_accuracy: 0.7689 - val_se_out_accuracy: 0.7952\n",
      "Epoch 46/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.7554 - original_out_loss: 1.1094 - se_out_loss: 0.6459 - original_out_accuracy: 0.7015 - se_out_accuracy: 0.8198\n",
      "Epoch 00046: val_loss improved from 1.56803 to 1.44199, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 120s 360ms/step - loss: 1.7553 - original_out_loss: 1.1098 - se_out_loss: 0.6455 - original_out_accuracy: 0.7016 - se_out_accuracy: 0.8201 - val_loss: 1.4420 - val_original_out_loss: 0.8312 - val_se_out_loss: 0.6108 - val_original_out_accuracy: 0.7737 - val_se_out_accuracy: 0.8108\n",
      "Epoch 47/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.6901 - original_out_loss: 1.0542 - se_out_loss: 0.6359 - original_out_accuracy: 0.7212 - se_out_accuracy: 0.8143\n",
      "Epoch 00047: val_loss improved from 1.44199 to 1.42214, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 123s 369ms/step - loss: 1.6888 - original_out_loss: 1.0533 - se_out_loss: 0.6355 - original_out_accuracy: 0.7214 - se_out_accuracy: 0.8142 - val_loss: 1.4221 - val_original_out_loss: 0.8136 - val_se_out_loss: 0.6085 - val_original_out_accuracy: 0.7916 - val_se_out_accuracy: 0.8132\n",
      "Epoch 48/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.5947 - original_out_loss: 0.9898 - se_out_loss: 0.6048 - original_out_accuracy: 0.7375 - se_out_accuracy: 0.8233\n",
      "Epoch 00048: val_loss improved from 1.42214 to 1.36824, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 121s 362ms/step - loss: 1.5932 - original_out_loss: 0.9888 - se_out_loss: 0.6044 - original_out_accuracy: 0.7377 - se_out_accuracy: 0.8232 - val_loss: 1.3682 - val_original_out_loss: 0.7708 - val_se_out_loss: 0.5975 - val_original_out_accuracy: 0.7952 - val_se_out_accuracy: 0.8072\n",
      "Epoch 49/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.5090 - original_out_loss: 0.9341 - se_out_loss: 0.5749 - original_out_accuracy: 0.7452 - se_out_accuracy: 0.8314\n",
      "Epoch 00049: val_loss improved from 1.36824 to 1.34789, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 122s 366ms/step - loss: 1.5079 - original_out_loss: 0.9332 - se_out_loss: 0.5747 - original_out_accuracy: 0.7454 - se_out_accuracy: 0.8314 - val_loss: 1.3479 - val_original_out_loss: 0.7554 - val_se_out_loss: 0.5925 - val_original_out_accuracy: 0.7952 - val_se_out_accuracy: 0.8048\n",
      "Epoch 50/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.4149 - original_out_loss: 0.8571 - se_out_loss: 0.5578 - original_out_accuracy: 0.7644 - se_out_accuracy: 0.8372\n",
      "Epoch 00050: val_loss improved from 1.34789 to 1.31695, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 126s 377ms/step - loss: 1.4137 - original_out_loss: 0.8564 - se_out_loss: 0.5573 - original_out_accuracy: 0.7645 - se_out_accuracy: 0.8374 - val_loss: 1.3169 - val_original_out_loss: 0.7448 - val_se_out_loss: 0.5722 - val_original_out_accuracy: 0.7952 - val_se_out_accuracy: 0.8216\n",
      "Epoch 51/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.3609 - original_out_loss: 0.8335 - se_out_loss: 0.5274 - original_out_accuracy: 0.7677 - se_out_accuracy: 0.8456\n",
      "Epoch 00051: val_loss improved from 1.31695 to 1.28132, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 128s 384ms/step - loss: 1.3603 - original_out_loss: 0.8328 - se_out_loss: 0.5275 - original_out_accuracy: 0.7678 - se_out_accuracy: 0.8455 - val_loss: 1.2813 - val_original_out_loss: 0.7256 - val_se_out_loss: 0.5557 - val_original_out_accuracy: 0.8084 - val_se_out_accuracy: 0.8311\n",
      "Epoch 52/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.3321 - original_out_loss: 0.8030 - se_out_loss: 0.5292 - original_out_accuracy: 0.7823 - se_out_accuracy: 0.8461\n",
      "Epoch 00052: val_loss did not improve from 1.28132\n",
      "334/334 [==============================] - 122s 365ms/step - loss: 1.3305 - original_out_loss: 0.8016 - se_out_loss: 0.5289 - original_out_accuracy: 0.7826 - se_out_accuracy: 0.8461 - val_loss: 1.3370 - val_original_out_loss: 0.7711 - val_se_out_loss: 0.5660 - val_original_out_accuracy: 0.8072 - val_se_out_accuracy: 0.8287\n",
      "Epoch 53/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.2982 - original_out_loss: 0.7782 - se_out_loss: 0.5200 - original_out_accuracy: 0.7907 - se_out_accuracy: 0.8477\n",
      "Epoch 00053: val_loss did not improve from 1.28132\n",
      "334/334 [==============================] - 125s 375ms/step - loss: 1.2972 - original_out_loss: 0.7768 - se_out_loss: 0.5204 - original_out_accuracy: 0.7912 - se_out_accuracy: 0.8475 - val_loss: 1.2953 - val_original_out_loss: 0.7408 - val_se_out_loss: 0.5545 - val_original_out_accuracy: 0.8096 - val_se_out_accuracy: 0.8287\n",
      "Epoch 54/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.2330 - original_out_loss: 0.7460 - se_out_loss: 0.4871 - original_out_accuracy: 0.7946 - se_out_accuracy: 0.8550\n",
      "Epoch 00054: val_loss improved from 1.28132 to 1.25448, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 124s 371ms/step - loss: 1.2311 - original_out_loss: 0.7447 - se_out_loss: 0.4864 - original_out_accuracy: 0.7949 - se_out_accuracy: 0.8554 - val_loss: 1.2545 - val_original_out_loss: 0.7115 - val_se_out_loss: 0.5430 - val_original_out_accuracy: 0.8108 - val_se_out_accuracy: 0.8228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.2052 - original_out_loss: 0.7194 - se_out_loss: 0.4858 - original_out_accuracy: 0.8071 - se_out_accuracy: 0.8569\n",
      "Epoch 00055: val_loss did not improve from 1.25448\n",
      "334/334 [==============================] - 128s 383ms/step - loss: 1.2077 - original_out_loss: 0.7205 - se_out_loss: 0.4872 - original_out_accuracy: 0.8066 - se_out_accuracy: 0.8566 - val_loss: 1.3013 - val_original_out_loss: 0.7471 - val_se_out_loss: 0.5542 - val_original_out_accuracy: 0.8120 - val_se_out_accuracy: 0.8240\n",
      "Epoch 56/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.1774 - original_out_loss: 0.7018 - se_out_loss: 0.4757 - original_out_accuracy: 0.8081 - se_out_accuracy: 0.8610\n",
      "Epoch 00056: val_loss did not improve from 1.25448\n",
      "334/334 [==============================] - 129s 387ms/step - loss: 1.1792 - original_out_loss: 0.7024 - se_out_loss: 0.4769 - original_out_accuracy: 0.8081 - se_out_accuracy: 0.8606 - val_loss: 1.3107 - val_original_out_loss: 0.7566 - val_se_out_loss: 0.5541 - val_original_out_accuracy: 0.8168 - val_se_out_accuracy: 0.8204\n",
      "Epoch 57/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.1621 - original_out_loss: 0.6883 - se_out_loss: 0.4738 - original_out_accuracy: 0.8078 - se_out_accuracy: 0.8568\n",
      "Epoch 00057: val_loss did not improve from 1.25448\n",
      "334/334 [==============================] - 121s 364ms/step - loss: 1.1652 - original_out_loss: 0.6900 - se_out_loss: 0.4752 - original_out_accuracy: 0.8075 - se_out_accuracy: 0.8566 - val_loss: 1.3116 - val_original_out_loss: 0.7503 - val_se_out_loss: 0.5613 - val_original_out_accuracy: 0.8096 - val_se_out_accuracy: 0.8216\n",
      "Epoch 58/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0764 - original_out_loss: 0.6263 - se_out_loss: 0.4502 - original_out_accuracy: 0.8243 - se_out_accuracy: 0.8655\n",
      "Epoch 00058: val_loss did not improve from 1.25448\n",
      "334/334 [==============================] - 122s 366ms/step - loss: 1.0762 - original_out_loss: 0.6258 - se_out_loss: 0.4503 - original_out_accuracy: 0.8243 - se_out_accuracy: 0.8653 - val_loss: 1.2640 - val_original_out_loss: 0.7234 - val_se_out_loss: 0.5406 - val_original_out_accuracy: 0.8120 - val_se_out_accuracy: 0.8275\n",
      "Epoch 59/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0764 - original_out_loss: 0.6337 - se_out_loss: 0.4427 - original_out_accuracy: 0.8186 - se_out_accuracy: 0.8698\n",
      "Epoch 00059: val_loss did not improve from 1.25448\n",
      "334/334 [==============================] - 117s 351ms/step - loss: 1.0773 - original_out_loss: 0.6334 - se_out_loss: 0.4440 - original_out_accuracy: 0.8187 - se_out_accuracy: 0.8693 - val_loss: 1.2561 - val_original_out_loss: 0.7271 - val_se_out_loss: 0.5290 - val_original_out_accuracy: 0.8251 - val_se_out_accuracy: 0.8323\n",
      "Epoch 60/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0464 - original_out_loss: 0.6282 - se_out_loss: 0.4182 - original_out_accuracy: 0.8191 - se_out_accuracy: 0.8791\n",
      "Epoch 00060: val_loss improved from 1.25448 to 1.22951, saving model to saved_models/weights.best.MobileNetV2_warmup.hdf5\n",
      "334/334 [==============================] - 122s 365ms/step - loss: 1.0447 - original_out_loss: 0.6271 - se_out_loss: 0.4176 - original_out_accuracy: 0.8193 - se_out_accuracy: 0.8793 - val_loss: 1.2295 - val_original_out_loss: 0.7011 - val_se_out_loss: 0.5284 - val_original_out_accuracy: 0.8275 - val_se_out_accuracy: 0.8192\n",
      "Epoch 61/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0184 - original_out_loss: 0.5921 - se_out_loss: 0.4263 - original_out_accuracy: 0.8366 - se_out_accuracy: 0.8749\n",
      "Epoch 00061: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 121s 364ms/step - loss: 1.0174 - original_out_loss: 0.5914 - se_out_loss: 0.4260 - original_out_accuracy: 0.8370 - se_out_accuracy: 0.8749 - val_loss: 1.2723 - val_original_out_loss: 0.7336 - val_se_out_loss: 0.5387 - val_original_out_accuracy: 0.8168 - val_se_out_accuracy: 0.8335\n",
      "Epoch 62/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9966 - original_out_loss: 0.5770 - se_out_loss: 0.4196 - original_out_accuracy: 0.8381 - se_out_accuracy: 0.8754\n",
      "Epoch 00062: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 123s 369ms/step - loss: 0.9950 - original_out_loss: 0.5758 - se_out_loss: 0.4192 - original_out_accuracy: 0.8385 - se_out_accuracy: 0.8754 - val_loss: 1.3032 - val_original_out_loss: 0.7614 - val_se_out_loss: 0.5418 - val_original_out_accuracy: 0.8192 - val_se_out_accuracy: 0.8240\n",
      "Epoch 63/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0296 - original_out_loss: 0.6030 - se_out_loss: 0.4266 - original_out_accuracy: 0.8324 - se_out_accuracy: 0.8707\n",
      "Epoch 00063: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 124s 371ms/step - loss: 1.0300 - original_out_loss: 0.6027 - se_out_loss: 0.4273 - original_out_accuracy: 0.8326 - se_out_accuracy: 0.8704 - val_loss: 1.2808 - val_original_out_loss: 0.7493 - val_se_out_loss: 0.5315 - val_original_out_accuracy: 0.8228 - val_se_out_accuracy: 0.8323\n",
      "Epoch 64/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9550 - original_out_loss: 0.5496 - se_out_loss: 0.4054 - original_out_accuracy: 0.8429 - se_out_accuracy: 0.8812\n",
      "Epoch 00064: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 121s 363ms/step - loss: 0.9558 - original_out_loss: 0.5499 - se_out_loss: 0.4060 - original_out_accuracy: 0.8428 - se_out_accuracy: 0.8810 - val_loss: 1.2382 - val_original_out_loss: 0.7169 - val_se_out_loss: 0.5212 - val_original_out_accuracy: 0.8299 - val_se_out_accuracy: 0.8311\n",
      "Epoch 65/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8944 - original_out_loss: 0.5121 - se_out_loss: 0.3823 - original_out_accuracy: 0.8527 - se_out_accuracy: 0.8874\n",
      "Epoch 00065: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 122s 366ms/step - loss: 0.8965 - original_out_loss: 0.5137 - se_out_loss: 0.3827 - original_out_accuracy: 0.8525 - se_out_accuracy: 0.8873 - val_loss: 1.2906 - val_original_out_loss: 0.7582 - val_se_out_loss: 0.5324 - val_original_out_accuracy: 0.8240 - val_se_out_accuracy: 0.8240\n",
      "Epoch 66/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9082 - original_out_loss: 0.5281 - se_out_loss: 0.3802 - original_out_accuracy: 0.8494 - se_out_accuracy: 0.8860\n",
      "Epoch 00066: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 119s 355ms/step - loss: 0.9077 - original_out_loss: 0.5278 - se_out_loss: 0.3799 - original_out_accuracy: 0.8494 - se_out_accuracy: 0.8859 - val_loss: 1.2619 - val_original_out_loss: 0.7407 - val_se_out_loss: 0.5212 - val_original_out_accuracy: 0.8263 - val_se_out_accuracy: 0.8263\n",
      "Epoch 67/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8939 - original_out_loss: 0.5155 - se_out_loss: 0.3784 - original_out_accuracy: 0.8532 - se_out_accuracy: 0.8863\n",
      "Epoch 00067: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 121s 363ms/step - loss: 0.8943 - original_out_loss: 0.5154 - se_out_loss: 0.3789 - original_out_accuracy: 0.8533 - se_out_accuracy: 0.8862 - val_loss: 1.2696 - val_original_out_loss: 0.7444 - val_se_out_loss: 0.5252 - val_original_out_accuracy: 0.8240 - val_se_out_accuracy: 0.8311\n",
      "Epoch 68/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8795 - original_out_loss: 0.5101 - se_out_loss: 0.3694 - original_out_accuracy: 0.8559 - se_out_accuracy: 0.8887\n",
      "Epoch 00068: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 120s 359ms/step - loss: 0.8783 - original_out_loss: 0.5092 - se_out_loss: 0.3691 - original_out_accuracy: 0.8561 - se_out_accuracy: 0.8888 - val_loss: 1.2586 - val_original_out_loss: 0.7299 - val_se_out_loss: 0.5288 - val_original_out_accuracy: 0.8311 - val_se_out_accuracy: 0.8335\n",
      "Epoch 69/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.7942 - original_out_loss: 0.4449 - se_out_loss: 0.3493 - original_out_accuracy: 0.8683 - se_out_accuracy: 0.8950\n",
      "Epoch 00069: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 119s 355ms/step - loss: 0.7927 - original_out_loss: 0.4440 - se_out_loss: 0.3487 - original_out_accuracy: 0.8686 - se_out_accuracy: 0.8954 - val_loss: 1.2731 - val_original_out_loss: 0.7495 - val_se_out_loss: 0.5235 - val_original_out_accuracy: 0.8323 - val_se_out_accuracy: 0.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8333 - original_out_loss: 0.4731 - se_out_loss: 0.3602 - original_out_accuracy: 0.8662 - se_out_accuracy: 0.8878\n",
      "Epoch 00070: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 116s 348ms/step - loss: 0.8319 - original_out_loss: 0.4724 - se_out_loss: 0.3595 - original_out_accuracy: 0.8665 - se_out_accuracy: 0.8882 - val_loss: 1.2843 - val_original_out_loss: 0.7570 - val_se_out_loss: 0.5273 - val_original_out_accuracy: 0.8299 - val_se_out_accuracy: 0.8311\n",
      "Epoch 71/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8188 - original_out_loss: 0.4789 - se_out_loss: 0.3399 - original_out_accuracy: 0.8649 - se_out_accuracy: 0.8986\n",
      "Epoch 00071: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 119s 355ms/step - loss: 0.8174 - original_out_loss: 0.4780 - se_out_loss: 0.3394 - original_out_accuracy: 0.8650 - se_out_accuracy: 0.8990 - val_loss: 1.2826 - val_original_out_loss: 0.7585 - val_se_out_loss: 0.5241 - val_original_out_accuracy: 0.8251 - val_se_out_accuracy: 0.8323\n",
      "Epoch 72/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8001 - original_out_loss: 0.4625 - se_out_loss: 0.3376 - original_out_accuracy: 0.8671 - se_out_accuracy: 0.8955\n",
      "Epoch 00072: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 123s 370ms/step - loss: 0.7995 - original_out_loss: 0.4619 - se_out_loss: 0.3376 - original_out_accuracy: 0.8672 - se_out_accuracy: 0.8955 - val_loss: 1.2614 - val_original_out_loss: 0.7396 - val_se_out_loss: 0.5219 - val_original_out_accuracy: 0.8251 - val_se_out_accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.8061 - original_out_loss: 0.4565 - se_out_loss: 0.3496 - original_out_accuracy: 0.8698 - se_out_accuracy: 0.8971\n",
      "Epoch 00073: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 120s 360ms/step - loss: 0.8058 - original_out_loss: 0.4567 - se_out_loss: 0.3491 - original_out_accuracy: 0.8698 - se_out_accuracy: 0.8975 - val_loss: 1.2444 - val_original_out_loss: 0.7256 - val_se_out_loss: 0.5188 - val_original_out_accuracy: 0.8359 - val_se_out_accuracy: 0.8395\n",
      "Epoch 74/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.7701 - original_out_loss: 0.4428 - se_out_loss: 0.3273 - original_out_accuracy: 0.8752 - se_out_accuracy: 0.9012\n",
      "Epoch 00074: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 123s 369ms/step - loss: 0.7692 - original_out_loss: 0.4424 - se_out_loss: 0.3268 - original_out_accuracy: 0.8753 - se_out_accuracy: 0.9013 - val_loss: 1.2828 - val_original_out_loss: 0.7522 - val_se_out_loss: 0.5306 - val_original_out_accuracy: 0.8323 - val_se_out_accuracy: 0.8323\n",
      "Epoch 75/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.7784 - original_out_loss: 0.4412 - se_out_loss: 0.3371 - original_out_accuracy: 0.8733 - se_out_accuracy: 0.8979\n",
      "Epoch 00075: val_loss did not improve from 1.22951\n",
      "334/334 [==============================] - 122s 364ms/step - loss: 0.7772 - original_out_loss: 0.4405 - se_out_loss: 0.3367 - original_out_accuracy: 0.8735 - se_out_accuracy: 0.8981 - val_loss: 1.2645 - val_original_out_loss: 0.7397 - val_se_out_loss: 0.5248 - val_original_out_accuracy: 0.8347 - val_se_out_accuracy: 0.8407\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=100,\n",
    "                                       callbacks=[tensorboard_callback, early_stop, checkpointer],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('saved_models/weights.best.MobileNetV2_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.MobileNetV2_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 45s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prediction(predictions, weights=[1.,1.]):\n",
    "    predictions = np.array(predictions)\n",
    "    weights = np.array(weights).reshape(predictions.shape[0], 1, 1)\n",
    "    return np.mean(predictions * weights, axis=0)\n",
    "\n",
    "def cal_accuracy(predictions, truth):\n",
    "    if type(predictions) != list:\n",
    "        predictions = [predictions]\n",
    "    accuracy = []\n",
    "    for prediction in predictions:\n",
    "        prediction = np.argmax(prediction, axis=-1)\n",
    "        correct_nums = (prediction == truth).sum()\n",
    "        accuracy.append(correct_nums / len(prediction))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8325358851674641]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.MobileNetV2_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 40s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8325358851674641]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Augmentors\n",
    "tta_augmentors = [iaa.Fliplr(1.), iaa.Flipud(1.)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=1, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'], tta_augmentors=tta_augmentors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836\r"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((df_test.shape[0], total_classes))\n",
    "count = 0\n",
    "total_len = len(tta_test_datagen)\n",
    "for images in tta_test_datagen:\n",
    "    count += 1\n",
    "    print(\"{}/{}\".format(count, total_len), end=\"\\r\")\n",
    "    preds = []\n",
    "    for image in images:\n",
    "        pred = model.predict_on_batch(image)\n",
    "        pred = combine_prediction(pred, [1.0, 1.0])\n",
    "        preds.append(pred)\n",
    "    all_predictions[count-1] = combine_prediction(preds, [1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7464114832535885]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(np.array(all_predictions).reshape((836, 133)), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 9s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict_generator(generator=val_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = combine_prediction(val_pred, [1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 22s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=2, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "test_pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n",
    "\n",
    "test_pred = combine_prediction(test_pred, [1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 133)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 133)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pseudolabels= np.argmax(val_pred, axis=-1)\n",
    "test_pseudolabels = np.argmax(test_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835,)\n",
      "(836,)\n"
     ]
    }
   ],
   "source": [
    "print(val_pseudolabels.shape)\n",
    "\n",
    "print(test_pseudolabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine pseudo labels with train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_data = pd.DataFrame({\"img_path\": np.concatenate([df_val['img_path'].values, df_test['img_path'].values]),\n",
    "                            \"label\": np.concatenate([val_pseudolabels, test_pseudolabels])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_train = pd.concat([pseudo_data, df_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8351, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_train_datagen = MultiOutputDataGenerator(images_paths=pseudo_train['img_path'].values, labels=pseudo_train['label'].values,\n",
    "                              batch_size=batch_size, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=create_augmenter(train=True), preprocessor=preprocess_input,\n",
    "                             return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.MobileNetV2_PL.hdf5', \n",
    "                                  verbose=1, save_best_only=True)\n",
    "\n",
    "logdir = f\".\\logs\\pseudolabeling\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                               mode=\"min\",\n",
    "                               patience=15,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.MobileNetV2_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "sgd = SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.4529 - original_out_loss: 1.8777 - se_out_loss: 1.5752 - original_out_accuracy: 0.7123 - se_out_accuracy: 0.7475\n",
      "Epoch 00001: val_loss improved from inf to 1.32282, saving model to saved_models/weights.best.MobileNetV2_PL.hdf5\n",
      "417/417 [==============================] - 143s 343ms/step - loss: 3.4560 - original_out_loss: 1.8793 - se_out_loss: 1.5767 - original_out_accuracy: 0.7124 - se_out_accuracy: 0.7474 - val_loss: 1.3228 - val_original_out_loss: 0.7056 - val_se_out_loss: 0.6172 - val_original_out_accuracy: 0.7976 - val_se_out_accuracy: 0.8120\n",
      "Epoch 2/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.3045 - original_out_loss: 1.7560 - se_out_loss: 1.5485 - original_out_accuracy: 0.7149 - se_out_accuracy: 0.7466\n",
      "Epoch 00002: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 144s 345ms/step - loss: 3.3046 - original_out_loss: 1.7563 - se_out_loss: 1.5483 - original_out_accuracy: 0.7152 - se_out_accuracy: 0.7468 - val_loss: 1.4365 - val_original_out_loss: 0.7456 - val_se_out_loss: 0.6909 - val_original_out_accuracy: 0.7940 - val_se_out_accuracy: 0.8000\n",
      "Epoch 3/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.1630 - original_out_loss: 1.6825 - se_out_loss: 1.4804 - original_out_accuracy: 0.7218 - se_out_accuracy: 0.7559\n",
      "Epoch 00003: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 147s 352ms/step - loss: 3.1639 - original_out_loss: 1.6830 - se_out_loss: 1.4809 - original_out_accuracy: 0.7219 - se_out_accuracy: 0.7560 - val_loss: 1.6039 - val_original_out_loss: 0.7765 - val_se_out_loss: 0.8275 - val_original_out_accuracy: 0.7772 - val_se_out_accuracy: 0.7868\n",
      "Epoch 4/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.0696 - original_out_loss: 1.6151 - se_out_loss: 1.4545 - original_out_accuracy: 0.7268 - se_out_accuracy: 0.7535\n",
      "Epoch 00004: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 142s 340ms/step - loss: 3.0694 - original_out_loss: 1.6151 - se_out_loss: 1.4543 - original_out_accuracy: 0.7267 - se_out_accuracy: 0.7537 - val_loss: 1.6678 - val_original_out_loss: 0.7963 - val_se_out_loss: 0.8715 - val_original_out_accuracy: 0.7689 - val_se_out_accuracy: 0.7940\n",
      "Epoch 5/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 3.0012 - original_out_loss: 1.5772 - se_out_loss: 1.4239 - original_out_accuracy: 0.7306 - se_out_accuracy: 0.7589\n",
      "Epoch 00005: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 143s 342ms/step - loss: 2.9983 - original_out_loss: 1.5758 - se_out_loss: 1.4225 - original_out_accuracy: 0.7307 - se_out_accuracy: 0.7592 - val_loss: 1.7526 - val_original_out_loss: 0.8384 - val_se_out_loss: 0.9142 - val_original_out_accuracy: 0.7593 - val_se_out_accuracy: 0.7701\n",
      "Epoch 6/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.8772 - original_out_loss: 1.4939 - se_out_loss: 1.3834 - original_out_accuracy: 0.7431 - se_out_accuracy: 0.7708\n",
      "Epoch 00006: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 146s 351ms/step - loss: 2.8797 - original_out_loss: 1.4955 - se_out_loss: 1.3842 - original_out_accuracy: 0.7428 - se_out_accuracy: 0.7705 - val_loss: 1.7869 - val_original_out_loss: 0.8362 - val_se_out_loss: 0.9506 - val_original_out_accuracy: 0.7653 - val_se_out_accuracy: 0.7904\n",
      "Epoch 7/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.8044 - original_out_loss: 1.4596 - se_out_loss: 1.3448 - original_out_accuracy: 0.7397 - se_out_accuracy: 0.7719\n",
      "Epoch 00007: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 145s 349ms/step - loss: 2.8006 - original_out_loss: 1.4572 - se_out_loss: 1.3435 - original_out_accuracy: 0.7400 - se_out_accuracy: 0.7721 - val_loss: 1.8459 - val_original_out_loss: 0.8765 - val_se_out_loss: 0.9693 - val_original_out_accuracy: 0.7509 - val_se_out_accuracy: 0.7916\n",
      "Epoch 8/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.7382 - original_out_loss: 1.4225 - se_out_loss: 1.3158 - original_out_accuracy: 0.7427 - se_out_accuracy: 0.7745\n",
      "Epoch 00008: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 145s 348ms/step - loss: 2.7384 - original_out_loss: 1.4232 - se_out_loss: 1.3153 - original_out_accuracy: 0.7424 - se_out_accuracy: 0.7747 - val_loss: 2.1078 - val_original_out_loss: 1.0075 - val_se_out_loss: 1.1002 - val_original_out_accuracy: 0.7413 - val_se_out_accuracy: 0.7808\n",
      "Epoch 9/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.6679 - original_out_loss: 1.3784 - se_out_loss: 1.2896 - original_out_accuracy: 0.7567 - se_out_accuracy: 0.7811\n",
      "Epoch 00009: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 142s 340ms/step - loss: 2.6656 - original_out_loss: 1.3768 - se_out_loss: 1.2888 - original_out_accuracy: 0.7570 - se_out_accuracy: 0.7813 - val_loss: 2.0779 - val_original_out_loss: 1.0066 - val_se_out_loss: 1.0713 - val_original_out_accuracy: 0.7425 - val_se_out_accuracy: 0.7820\n",
      "Epoch 10/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.5797 - original_out_loss: 1.3190 - se_out_loss: 1.2608 - original_out_accuracy: 0.7520 - se_out_accuracy: 0.7852\n",
      "Epoch 00010: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 146s 351ms/step - loss: 2.5827 - original_out_loss: 1.3214 - se_out_loss: 1.2614 - original_out_accuracy: 0.7518 - se_out_accuracy: 0.7853 - val_loss: 2.2264 - val_original_out_loss: 1.0738 - val_se_out_loss: 1.1525 - val_original_out_accuracy: 0.7174 - val_se_out_accuracy: 0.7593\n",
      "Epoch 11/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.5387 - original_out_loss: 1.3055 - se_out_loss: 1.2332 - original_out_accuracy: 0.7572 - se_out_accuracy: 0.7852\n",
      "Epoch 00011: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 146s 350ms/step - loss: 2.5404 - original_out_loss: 1.3062 - se_out_loss: 1.2342 - original_out_accuracy: 0.7566 - se_out_accuracy: 0.7848 - val_loss: 2.4424 - val_original_out_loss: 1.1934 - val_se_out_loss: 1.2490 - val_original_out_accuracy: 0.7030 - val_se_out_accuracy: 0.7473\n",
      "Epoch 12/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.4438 - original_out_loss: 1.2453 - se_out_loss: 1.1985 - original_out_accuracy: 0.7609 - se_out_accuracy: 0.7892\n",
      "Epoch 00012: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 145s 347ms/step - loss: 2.4446 - original_out_loss: 1.2456 - se_out_loss: 1.1991 - original_out_accuracy: 0.7609 - se_out_accuracy: 0.7891 - val_loss: 2.5544 - val_original_out_loss: 1.2361 - val_se_out_loss: 1.3183 - val_original_out_accuracy: 0.6934 - val_se_out_accuracy: 0.7401\n",
      "Epoch 13/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.4054 - original_out_loss: 1.2172 - se_out_loss: 1.1883 - original_out_accuracy: 0.7696 - se_out_accuracy: 0.7903\n",
      "Epoch 00013: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 145s 348ms/step - loss: 2.4038 - original_out_loss: 1.2159 - se_out_loss: 1.1879 - original_out_accuracy: 0.7699 - se_out_accuracy: 0.7902 - val_loss: 2.4303 - val_original_out_loss: 1.2015 - val_se_out_loss: 1.2288 - val_original_out_accuracy: 0.7198 - val_se_out_accuracy: 0.7533\n",
      "Epoch 14/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.3650 - original_out_loss: 1.1974 - se_out_loss: 1.1676 - original_out_accuracy: 0.7690 - se_out_accuracy: 0.7881\n",
      "Epoch 00014: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 149s 357ms/step - loss: 2.3694 - original_out_loss: 1.1997 - se_out_loss: 1.1697 - original_out_accuracy: 0.7688 - se_out_accuracy: 0.7879 - val_loss: 2.8006 - val_original_out_loss: 1.3956 - val_se_out_loss: 1.4050 - val_original_out_accuracy: 0.6527 - val_se_out_accuracy: 0.7341\n",
      "Epoch 15/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.3115 - original_out_loss: 1.1614 - se_out_loss: 1.1501 - original_out_accuracy: 0.7745 - se_out_accuracy: 0.7935\n",
      "Epoch 00015: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 152s 364ms/step - loss: 2.3167 - original_out_loss: 1.1641 - se_out_loss: 1.1526 - original_out_accuracy: 0.7741 - se_out_accuracy: 0.7930 - val_loss: 2.6235 - val_original_out_loss: 1.3397 - val_se_out_loss: 1.2838 - val_original_out_accuracy: 0.6659 - val_se_out_accuracy: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.2207 - original_out_loss: 1.1193 - se_out_loss: 1.1014 - original_out_accuracy: 0.7831 - se_out_accuracy: 0.8004\n",
      "Epoch 00016: val_loss did not improve from 1.32282\n",
      "417/417 [==============================] - 143s 344ms/step - loss: 2.2239 - original_out_loss: 1.1202 - se_out_loss: 1.1036 - original_out_accuracy: 0.7826 - se_out_accuracy: 0.8000 - val_loss: 2.7713 - val_original_out_loss: 1.4434 - val_se_out_loss: 1.3280 - val_original_out_accuracy: 0.6359 - val_se_out_accuracy: 0.7042\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=pseudo_train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=100,\n",
    "                                       callbacks=[tensorboard_callback, early_stop, checkpointer, lr_scheduler],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 21s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8301435406698564]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.MobileNetV2_PL.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 21s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8301435406698564]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n",
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify model for deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.MobileNetV2_whole_model.hdf5')\n",
    "sgd = SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_output = Average()(model.output)\n",
    "combined_model = Model(inputs=model.input, outputs=combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'average/Identity:0' shape=(None, 133) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = BaseDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=1, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 13s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = combined_model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8325358851674641]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(pred, df_test['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.save_weights('saved_models/weights.best.MobileNetV2_combined.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
