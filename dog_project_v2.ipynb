{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Concatenate, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Permute, multiply\n",
    "#from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TensorBoard, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_augmenter(train=True):\n",
    "    # from https://github.com/aleju/imgaug\n",
    "    # Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "    # e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "    # Define our sequence of augmentation steps that will be applied to every image\n",
    "    # All augmenters with per_channel=0.5 will sample one value _per image_\n",
    "    # in 50% of all cases. In all other cases they will sample new values\n",
    "    # _per channel_.\n",
    "    if train:\n",
    "        seq = iaa.Sequential(\n",
    "            [\n",
    "                # apply the following augmenters to most images\n",
    "                iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "                iaa.Flipud(0.2), # vertically flip 20% of all images\n",
    "                # crop images by -5% to 10% of their height/width\n",
    "                sometimes(iaa.CropAndPad(\n",
    "                    percent=(-0.05, 0.1),\n",
    "                    pad_mode=ia.ALL, # random mode from all available modes will be sampled per image.\n",
    "                    pad_cval=(0, 255) # The constant value to use if the pad mode is constant or the end value to use if the mode is linear_ramp\n",
    "                )),\n",
    "                sometimes(iaa.Affine(\n",
    "                    scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "                    rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                    shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "                    cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "                    mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "                )),\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        pass\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/mpalermo/keras-pipeline-custom-generator-imgaug\n",
    "class BaseDataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images_paths, labels, batch_size=64, image_dimensions = (512, 512, 3),\n",
    "                 shuffle=False, augmenter=None, preprocessor=None,\n",
    "                 return_label=True, total_classes=None):\n",
    "        self.labels       = labels              # array of labels\n",
    "        self.images_paths = images_paths        # array of image paths\n",
    "        self.dim          = image_dimensions    # image dimensions\n",
    "        self.batch_size   = batch_size          # batch size\n",
    "        self.shuffle      = shuffle             # shuffle bool\n",
    "        self.augmenter      = augmenter           # augmenter\n",
    "        self.preprocessor = preprocessor\n",
    "        self.return_label = return_label\n",
    "        self.total_classes = total_classes\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images_paths) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.images_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def gather_batch_item(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # selects indices of data for next batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # select data and load images\n",
    "        images = [cv2.imread(self.images_paths[k]) for k in indexes]\n",
    "\n",
    "        # preprocess and augment data\n",
    "        if self.augmenter:\n",
    "            images = self.augmenter.augment_images(images)\n",
    "\n",
    "        images= np.array([self.preprocess_image(cv2.resize(img, self.dim[:2])) for img in images])\n",
    "        \n",
    "        if self.return_label:\n",
    "            labels = np.array([self.labels[k] for k in indexes])\n",
    "            labels = to_categorical(labels, num_classes=self.total_classes)\n",
    "            return images, labels\n",
    "        else:\n",
    "            return images\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.gather_batch_item(index)\n",
    "        \n",
    "    def preprocess_image(self, images):\n",
    "        if self.preprocessor is None:\n",
    "            images = images / 255.\n",
    "            pass\n",
    "        else:\n",
    "            images = self.preprocessor(images)\n",
    "        return images\n",
    "    \n",
    "class MultiOutputDataGenerator(BaseDataGenerator):\n",
    "    'Generates multiple output data for Keras'\n",
    "    def __init__(self, images_paths, labels, batch_size=64, image_dimensions = (512, 512, 3),\n",
    "                 shuffle=False, augmenter=None, preprocessor=None,\n",
    "                 return_label=True, total_classes=None, output_names=None, tta_augmentors=None):\n",
    "        # Init parent's parameter\n",
    "        super().__init__(images_paths,\n",
    "                labels, batch_size, image_dimensions,\n",
    "                 shuffle, augmenter, preprocessor,\n",
    "                 return_label, total_classes)\n",
    "        \n",
    "        self.output_names = output_names\n",
    "        self.tta_augmentors = tta_augmentors\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.return_label:\n",
    "            images, labels = self.gather_batch_item(index)\n",
    "            output_dict = {}\n",
    "            # Copy labels to each output name\n",
    "            for output_name in self.output_names:\n",
    "                output_dict[output_name] = labels\n",
    "            if self.tta_augmentors != None:\n",
    "                images = self.get_tta_images(images)\n",
    "            return images, output_dict\n",
    "        else:\n",
    "            images = self.gather_batch_item(index)\n",
    "            if self.tta_augmentors != None:\n",
    "                images = self.get_tta_images(images)\n",
    "            return images\n",
    "    def get_tta_images(self, images):\n",
    "        aug_images = []\n",
    "        # Original\n",
    "        aug_images.append(images)\n",
    "        for augmentor in self.tta_augmentors:\n",
    "            aug_images.append(augmentor.augment_images(images))\n",
    "        images = aug_images\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xception pretrain model input size\n",
    "image_shape = (299, 299, 3)\n",
    "\n",
    "# 133\n",
    "total_classes = len(os.listdir('dogImages/train')) \n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_path_labels(path):\n",
    "    all_classes = os.listdir(path)\n",
    "    label_dict = {}\n",
    "    img_paths, label_list = [], []\n",
    "    for label_name in all_classes:\n",
    "        label_num, dog_name = label_name.split('.')\n",
    "        # Start with 0\n",
    "        label_num = int(label_num) - 1\n",
    "        label_dict[int(label_num)] = dog_name\n",
    "        for image_name in os.listdir(path + '/' + label_name):\n",
    "            img_paths.append(path + '/' + label_name + '/' + image_name)\n",
    "            label_list.append(label_num)\n",
    "    df = pd.DataFrame({'img_path': img_paths, 'label': label_list})\n",
    "    return label_dict, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_label_dict, df_train = create_path_labels('dogImages/train')\n",
    "_, df_val = create_path_labels('dogImages/valid')\n",
    "_, df_test = create_path_labels('dogImages/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Affenpinscher',\n",
       " 1: 'Afghan_hound',\n",
       " 2: 'Airedale_terrier',\n",
       " 3: 'Akita',\n",
       " 4: 'Alaskan_malamute',\n",
       " 5: 'American_eskimo_dog',\n",
       " 6: 'American_foxhound',\n",
       " 7: 'American_staffordshire_terrier',\n",
       " 8: 'American_water_spaniel',\n",
       " 9: 'Anatolian_shepherd_dog',\n",
       " 10: 'Australian_cattle_dog',\n",
       " 11: 'Australian_shepherd',\n",
       " 12: 'Australian_terrier',\n",
       " 13: 'Basenji',\n",
       " 14: 'Basset_hound',\n",
       " 15: 'Beagle',\n",
       " 16: 'Bearded_collie',\n",
       " 17: 'Beauceron',\n",
       " 18: 'Bedlington_terrier',\n",
       " 19: 'Belgian_malinois',\n",
       " 20: 'Belgian_sheepdog',\n",
       " 21: 'Belgian_tervuren',\n",
       " 22: 'Bernese_mountain_dog',\n",
       " 23: 'Bichon_frise',\n",
       " 24: 'Black_and_tan_coonhound',\n",
       " 25: 'Black_russian_terrier',\n",
       " 26: 'Bloodhound',\n",
       " 27: 'Bluetick_coonhound',\n",
       " 28: 'Border_collie',\n",
       " 29: 'Border_terrier',\n",
       " 30: 'Borzoi',\n",
       " 31: 'Boston_terrier',\n",
       " 32: 'Bouvier_des_flandres',\n",
       " 33: 'Boxer',\n",
       " 34: 'Boykin_spaniel',\n",
       " 35: 'Briard',\n",
       " 36: 'Brittany',\n",
       " 37: 'Brussels_griffon',\n",
       " 38: 'Bull_terrier',\n",
       " 39: 'Bulldog',\n",
       " 40: 'Bullmastiff',\n",
       " 41: 'Cairn_terrier',\n",
       " 42: 'Canaan_dog',\n",
       " 43: 'Cane_corso',\n",
       " 44: 'Cardigan_welsh_corgi',\n",
       " 45: 'Cavalier_king_charles_spaniel',\n",
       " 46: 'Chesapeake_bay_retriever',\n",
       " 47: 'Chihuahua',\n",
       " 48: 'Chinese_crested',\n",
       " 49: 'Chinese_shar-pei',\n",
       " 50: 'Chow_chow',\n",
       " 51: 'Clumber_spaniel',\n",
       " 52: 'Cocker_spaniel',\n",
       " 53: 'Collie',\n",
       " 54: 'Curly-coated_retriever',\n",
       " 55: 'Dachshund',\n",
       " 56: 'Dalmatian',\n",
       " 57: 'Dandie_dinmont_terrier',\n",
       " 58: 'Doberman_pinscher',\n",
       " 59: 'Dogue_de_bordeaux',\n",
       " 60: 'English_cocker_spaniel',\n",
       " 61: 'English_setter',\n",
       " 62: 'English_springer_spaniel',\n",
       " 63: 'English_toy_spaniel',\n",
       " 64: 'Entlebucher_mountain_dog',\n",
       " 65: 'Field_spaniel',\n",
       " 66: 'Finnish_spitz',\n",
       " 67: 'Flat-coated_retriever',\n",
       " 68: 'French_bulldog',\n",
       " 69: 'German_pinscher',\n",
       " 70: 'German_shepherd_dog',\n",
       " 71: 'German_shorthaired_pointer',\n",
       " 72: 'German_wirehaired_pointer',\n",
       " 73: 'Giant_schnauzer',\n",
       " 74: 'Glen_of_imaal_terrier',\n",
       " 75: 'Golden_retriever',\n",
       " 76: 'Gordon_setter',\n",
       " 77: 'Great_dane',\n",
       " 78: 'Great_pyrenees',\n",
       " 79: 'Greater_swiss_mountain_dog',\n",
       " 80: 'Greyhound',\n",
       " 81: 'Havanese',\n",
       " 82: 'Ibizan_hound',\n",
       " 83: 'Icelandic_sheepdog',\n",
       " 84: 'Irish_red_and_white_setter',\n",
       " 85: 'Irish_setter',\n",
       " 86: 'Irish_terrier',\n",
       " 87: 'Irish_water_spaniel',\n",
       " 88: 'Irish_wolfhound',\n",
       " 89: 'Italian_greyhound',\n",
       " 90: 'Japanese_chin',\n",
       " 91: 'Keeshond',\n",
       " 92: 'Kerry_blue_terrier',\n",
       " 93: 'Komondor',\n",
       " 94: 'Kuvasz',\n",
       " 95: 'Labrador_retriever',\n",
       " 96: 'Lakeland_terrier',\n",
       " 97: 'Leonberger',\n",
       " 98: 'Lhasa_apso',\n",
       " 99: 'Lowchen',\n",
       " 100: 'Maltese',\n",
       " 101: 'Manchester_terrier',\n",
       " 102: 'Mastiff',\n",
       " 103: 'Miniature_schnauzer',\n",
       " 104: 'Neapolitan_mastiff',\n",
       " 105: 'Newfoundland',\n",
       " 106: 'Norfolk_terrier',\n",
       " 107: 'Norwegian_buhund',\n",
       " 108: 'Norwegian_elkhound',\n",
       " 109: 'Norwegian_lundehund',\n",
       " 110: 'Norwich_terrier',\n",
       " 111: 'Nova_scotia_duck_tolling_retriever',\n",
       " 112: 'Old_english_sheepdog',\n",
       " 113: 'Otterhound',\n",
       " 114: 'Papillon',\n",
       " 115: 'Parson_russell_terrier',\n",
       " 116: 'Pekingese',\n",
       " 117: 'Pembroke_welsh_corgi',\n",
       " 118: 'Petit_basset_griffon_vendeen',\n",
       " 119: 'Pharaoh_hound',\n",
       " 120: 'Plott',\n",
       " 121: 'Pointer',\n",
       " 122: 'Pomeranian',\n",
       " 123: 'Poodle',\n",
       " 124: 'Portuguese_water_dog',\n",
       " 125: 'Saint_bernard',\n",
       " 126: 'Silky_terrier',\n",
       " 127: 'Smooth_fox_terrier',\n",
       " 128: 'Tibetan_mastiff',\n",
       " 129: 'Welsh_springer_spaniel',\n",
       " 130: 'Wirehaired_pointing_griffon',\n",
       " 131: 'Xoloitzcuintli',\n",
       " 132: 'Yorkshire_terrier'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>dogImages/train/001.Affenpinscher/Affenpinsche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path  label\n",
       "0  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "1  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "2  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "3  dogImages/train/001.Affenpinscher/Affenpinsche...      0\n",
       "4  dogImages/train/001.Affenpinscher/Affenpinsche...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6680, 2)\n",
      "(835, 2)\n",
      "(836, 2)\n"
     ]
    }
   ],
   "source": [
    "display(df_train.head())\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = MultiOutputDataGenerator(images_paths=df_train['img_path'].values, labels=df_train['label'].values,\n",
    "                              batch_size=batch_size, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=create_augmenter(train=True), preprocessor=preprocess_input,\n",
    "                             return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "val_datagen = MultiOutputDataGenerator(images_paths=df_val['img_path'].values, labels=df_val['label'].values,\n",
    "                              batch_size=5, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                                return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=1, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "167\n",
      "836\n"
     ]
    }
   ],
   "source": [
    "print(len(train_datagen))\n",
    "print(len(val_datagen))\n",
    "print(len(test_datagen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squeeze_excite_block(tensor, ratio=16):\n",
    "    # From: https://github.com/titu1994/keras-squeeze-excite-network\n",
    "    init = tensor\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = K.int_shape(init)[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pooling = None - output shape (None, 8, 8, 1536)\n",
    "# pooling = max  - output shape (None, 1536)\n",
    "# pooling = avg  - output shape (None, 1536)\n",
    "\n",
    "xception = Xception(include_top=False, weights='imagenet', input_shape=image_shape, pooling=None)\n",
    "x = xception.output\n",
    "\n",
    "# Original branch\n",
    "gavg = GlobalAveragePooling2D()(x)\n",
    "gmax = GlobalMaxPooling2D()(x)\n",
    "original_concat = Concatenate(axis=-1)([gavg, gmax,])\n",
    "original_concat = Dropout(0.5)(original_concat)\n",
    "original_final = Dense(total_classes, activation='softmax', name='original_out')(original_concat)\n",
    "\n",
    "# SE branch\n",
    "se_out = squeeze_excite_block(x)\n",
    "se_gavg = GlobalAveragePooling2D()(se_out)\n",
    "se_gmax = GlobalMaxPooling2D()(se_out)\n",
    "se_concat = Concatenate(axis=-1)([se_gavg, se_gmax,])\n",
    "se_concat = Dropout(0.5)(se_concat)\n",
    "se_final = Dense(total_classes, activation='softmax', name='se_out')(se_concat)\n",
    "\n",
    "model = Model(inputs=xception.input, outputs=[original_final, se_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1, 1, 2048)   0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1, 1, 128)    262144      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 1, 2048)   262144      dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 10, 10, 2048) 0           block14_sepconv2_act[0][0]       \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 2048)         0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 4096)         0           global_average_pooling2d_2[0][0] \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "original_out (Dense)            (None, 133)          544901      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "se_out (Dense)                  (None, 133)          544901      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,475,570\n",
      "Trainable params: 22,421,042\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception_best.hdf5', \n",
    "                                  verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "logdir = f\".\\logs\\warmup\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "    \n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                               mode=\"min\",\n",
    "                               patience=15,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "# Maybe useful, haven't tried\n",
    "def scheduler(epoch):\n",
    "    if epoch < 50:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 7.0953 - original_out_loss: 4.2644 - se_out_loss: 2.8309 - original_out_accuracy: 0.3278 - se_out_accuracy: 0.3772\n",
      "Epoch 00001: val_loss improved from inf to 1.92039, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 279s 835ms/step - loss: 7.0894 - original_out_loss: 4.2609 - se_out_loss: 2.8286 - original_out_accuracy: 0.3281 - se_out_accuracy: 0.3774 - val_loss: 1.9204 - val_original_out_loss: 1.0282 - val_se_out_loss: 0.8921 - val_original_out_accuracy: 0.7246 - val_se_out_accuracy: 0.7377\n",
      "Epoch 2/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.8835 - original_out_loss: 3.1104 - se_out_loss: 1.7730 - original_out_accuracy: 0.4893 - se_out_accuracy: 0.5506\n",
      "Epoch 00002: val_loss improved from 1.92039 to 1.58128, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 175s 524ms/step - loss: 4.8830 - original_out_loss: 3.1102 - se_out_loss: 1.7728 - original_out_accuracy: 0.4892 - se_out_accuracy: 0.5507 - val_loss: 1.5813 - val_original_out_loss: 0.8741 - val_se_out_loss: 0.7072 - val_original_out_accuracy: 0.7629 - val_se_out_accuracy: 0.7629\n",
      "Epoch 3/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.3360 - original_out_loss: 2.8113 - se_out_loss: 1.5246 - original_out_accuracy: 0.5428 - se_out_accuracy: 0.5968\n",
      "Epoch 00003: val_loss did not improve from 1.58128\n",
      "334/334 [==============================] - 171s 512ms/step - loss: 4.3340 - original_out_loss: 2.8089 - se_out_loss: 1.5251 - original_out_accuracy: 0.5431 - se_out_accuracy: 0.5970 - val_loss: 1.6030 - val_original_out_loss: 0.9235 - val_se_out_loss: 0.6795 - val_original_out_accuracy: 0.7485 - val_se_out_accuracy: 0.7856\n",
      "Epoch 4/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.3204 - original_out_loss: 2.9232 - se_out_loss: 1.3972 - original_out_accuracy: 0.5586 - se_out_accuracy: 0.6233\n",
      "Epoch 00004: val_loss improved from 1.58128 to 1.50135, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 173s 518ms/step - loss: 4.3197 - original_out_loss: 2.9231 - se_out_loss: 1.3966 - original_out_accuracy: 0.5584 - se_out_accuracy: 0.6235 - val_loss: 1.5013 - val_original_out_loss: 0.9261 - val_se_out_loss: 0.5753 - val_original_out_accuracy: 0.7641 - val_se_out_accuracy: 0.8096\n",
      "Epoch 5/5\n",
      "333/334 [============================>.] - ETA: 0s - loss: 4.2384 - original_out_loss: 2.8992 - se_out_loss: 1.3392 - original_out_accuracy: 0.5739 - se_out_accuracy: 0.6366\n",
      "Epoch 00005: val_loss improved from 1.50135 to 1.44479, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 173s 517ms/step - loss: 4.2453 - original_out_loss: 2.9044 - se_out_loss: 1.3408 - original_out_accuracy: 0.5734 - se_out_accuracy: 0.6358 - val_loss: 1.4448 - val_original_out_loss: 0.8585 - val_se_out_loss: 0.5863 - val_original_out_accuracy: 0.7796 - val_se_out_accuracy: 0.8228\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=5,\n",
    "                                       callbacks=[tensorboard_callback, early_stop, checkpointer],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = True\n",
    "\n",
    "logdir = f\".\\logs\\whole\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 2.1426 - original_out_loss: 1.1894 - se_out_loss: 0.9533 - original_out_accuracy: 0.6983 - se_out_accuracy: 0.7351\n",
      "Epoch 00001: val_loss improved from 1.44479 to 1.01614, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 207s 620ms/step - loss: 2.1399 - original_out_loss: 1.1879 - se_out_loss: 0.9520 - original_out_accuracy: 0.6987 - se_out_accuracy: 0.7353 - val_loss: 1.0161 - val_original_out_loss: 0.5506 - val_se_out_loss: 0.4656 - val_original_out_accuracy: 0.8359 - val_se_out_accuracy: 0.8527\n",
      "Epoch 2/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.3541 - original_out_loss: 0.7303 - se_out_loss: 0.6238 - original_out_accuracy: 0.7959 - se_out_accuracy: 0.8141\n",
      "Epoch 00002: val_loss improved from 1.01614 to 0.84061, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 208s 624ms/step - loss: 1.3536 - original_out_loss: 0.7300 - se_out_loss: 0.6236 - original_out_accuracy: 0.7958 - se_out_accuracy: 0.8142 - val_loss: 0.8406 - val_original_out_loss: 0.4588 - val_se_out_loss: 0.3818 - val_original_out_accuracy: 0.8611 - val_se_out_accuracy: 0.8826\n",
      "Epoch 3/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 1.0242 - original_out_loss: 0.5533 - se_out_loss: 0.4709 - original_out_accuracy: 0.8423 - se_out_accuracy: 0.8589\n",
      "Epoch 00003: val_loss did not improve from 0.84061\n",
      "334/334 [==============================] - 206s 616ms/step - loss: 1.0240 - original_out_loss: 0.5534 - se_out_loss: 0.4706 - original_out_accuracy: 0.8424 - se_out_accuracy: 0.8588 - val_loss: 0.8796 - val_original_out_loss: 0.5012 - val_se_out_loss: 0.3784 - val_original_out_accuracy: 0.8623 - val_se_out_accuracy: 0.8754\n",
      "Epoch 4/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.9078 - original_out_loss: 0.4913 - se_out_loss: 0.4165 - original_out_accuracy: 0.8553 - se_out_accuracy: 0.8766\n",
      "Epoch 00004: val_loss did not improve from 0.84061\n",
      "334/334 [==============================] - 210s 629ms/step - loss: 0.9082 - original_out_loss: 0.4917 - se_out_loss: 0.4165 - original_out_accuracy: 0.8552 - se_out_accuracy: 0.8765 - val_loss: 0.8607 - val_original_out_loss: 0.4963 - val_se_out_loss: 0.3644 - val_original_out_accuracy: 0.8659 - val_se_out_accuracy: 0.8850\n",
      "Epoch 5/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.7470 - original_out_loss: 0.4073 - se_out_loss: 0.3397 - original_out_accuracy: 0.8772 - se_out_accuracy: 0.8943\n",
      "Epoch 00005: val_loss did not improve from 0.84061\n",
      "334/334 [==============================] - 211s 633ms/step - loss: 0.7492 - original_out_loss: 0.4089 - se_out_loss: 0.3403 - original_out_accuracy: 0.8769 - se_out_accuracy: 0.8942 - val_loss: 0.8994 - val_original_out_loss: 0.5253 - val_se_out_loss: 0.3740 - val_original_out_accuracy: 0.8611 - val_se_out_accuracy: 0.8778\n",
      "Epoch 6/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.6860 - original_out_loss: 0.3723 - se_out_loss: 0.3138 - original_out_accuracy: 0.8908 - se_out_accuracy: 0.9059\n",
      "Epoch 00006: val_loss did not improve from 0.84061\n",
      "334/334 [==============================] - 211s 633ms/step - loss: 0.6862 - original_out_loss: 0.3725 - se_out_loss: 0.3137 - original_out_accuracy: 0.8906 - se_out_accuracy: 0.9057 - val_loss: 1.0026 - val_original_out_loss: 0.5958 - val_se_out_loss: 0.4068 - val_original_out_accuracy: 0.8527 - val_se_out_accuracy: 0.8635\n",
      "Epoch 7/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.5749 - original_out_loss: 0.3079 - se_out_loss: 0.2670 - original_out_accuracy: 0.9063 - se_out_accuracy: 0.9188\n",
      "Epoch 00007: val_loss improved from 0.84061 to 0.83524, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 214s 640ms/step - loss: 0.5748 - original_out_loss: 0.3075 - se_out_loss: 0.2673 - original_out_accuracy: 0.9064 - se_out_accuracy: 0.9187 - val_loss: 0.8352 - val_original_out_loss: 0.4914 - val_se_out_loss: 0.3438 - val_original_out_accuracy: 0.8790 - val_se_out_accuracy: 0.8946\n",
      "Epoch 8/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.5050 - original_out_loss: 0.2664 - se_out_loss: 0.2386 - original_out_accuracy: 0.9209 - se_out_accuracy: 0.9297\n",
      "Epoch 00008: val_loss did not improve from 0.83524\n",
      "334/334 [==============================] - 214s 640ms/step - loss: 0.5056 - original_out_loss: 0.2667 - se_out_loss: 0.2389 - original_out_accuracy: 0.9208 - se_out_accuracy: 0.9295 - val_loss: 0.9099 - val_original_out_loss: 0.5556 - val_se_out_loss: 0.3543 - val_original_out_accuracy: 0.8683 - val_se_out_accuracy: 0.8838\n",
      "Epoch 9/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.4601 - original_out_loss: 0.2460 - se_out_loss: 0.2141 - original_out_accuracy: 0.9270 - se_out_accuracy: 0.9366\n",
      "Epoch 00009: val_loss improved from 0.83524 to 0.81592, saving model to saved_models/weights.best.Xception.hdf5\n",
      "334/334 [==============================] - 214s 642ms/step - loss: 0.4600 - original_out_loss: 0.2458 - se_out_loss: 0.2142 - original_out_accuracy: 0.9269 - se_out_accuracy: 0.9365 - val_loss: 0.8159 - val_original_out_loss: 0.4784 - val_se_out_loss: 0.3375 - val_original_out_accuracy: 0.8778 - val_se_out_accuracy: 0.8850\n",
      "Epoch 10/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.4082 - original_out_loss: 0.2116 - se_out_loss: 0.1966 - original_out_accuracy: 0.9345 - se_out_accuracy: 0.9422\n",
      "Epoch 00010: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 214s 640ms/step - loss: 0.4087 - original_out_loss: 0.2121 - se_out_loss: 0.1966 - original_out_accuracy: 0.9344 - se_out_accuracy: 0.9422 - val_loss: 0.9183 - val_original_out_loss: 0.5620 - val_se_out_loss: 0.3563 - val_original_out_accuracy: 0.8826 - val_se_out_accuracy: 0.8862\n",
      "Epoch 11/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3681 - original_out_loss: 0.1975 - se_out_loss: 0.1706 - original_out_accuracy: 0.9420 - se_out_accuracy: 0.9495\n",
      "Epoch 00011: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 219s 656ms/step - loss: 0.3671 - original_out_loss: 0.1969 - se_out_loss: 0.1702 - original_out_accuracy: 0.9422 - se_out_accuracy: 0.9497 - val_loss: 0.8799 - val_original_out_loss: 0.5291 - val_se_out_loss: 0.3508 - val_original_out_accuracy: 0.8683 - val_se_out_accuracy: 0.8743\n",
      "Epoch 12/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3352 - original_out_loss: 0.1708 - se_out_loss: 0.1644 - original_out_accuracy: 0.9458 - se_out_accuracy: 0.9498\n",
      "Epoch 00012: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 218s 652ms/step - loss: 0.3352 - original_out_loss: 0.1710 - se_out_loss: 0.1642 - original_out_accuracy: 0.9458 - se_out_accuracy: 0.9500 - val_loss: 0.8806 - val_original_out_loss: 0.5337 - val_se_out_loss: 0.3469 - val_original_out_accuracy: 0.8719 - val_se_out_accuracy: 0.8934\n",
      "Epoch 13/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.3248 - original_out_loss: 0.1757 - se_out_loss: 0.1491 - original_out_accuracy: 0.9471 - se_out_accuracy: 0.9556\n",
      "Epoch 00013: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 223s 668ms/step - loss: 0.3245 - original_out_loss: 0.1756 - se_out_loss: 0.1490 - original_out_accuracy: 0.9472 - se_out_accuracy: 0.9555 - val_loss: 0.9087 - val_original_out_loss: 0.5496 - val_se_out_loss: 0.3591 - val_original_out_accuracy: 0.8850 - val_se_out_accuracy: 0.8874\n",
      "Epoch 14/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2847 - original_out_loss: 0.1531 - se_out_loss: 0.1316 - original_out_accuracy: 0.9526 - se_out_accuracy: 0.9607\n",
      "Epoch 00014: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 225s 674ms/step - loss: 0.2842 - original_out_loss: 0.1529 - se_out_loss: 0.1314 - original_out_accuracy: 0.9527 - se_out_accuracy: 0.9608 - val_loss: 0.8337 - val_original_out_loss: 0.5001 - val_se_out_loss: 0.3336 - val_original_out_accuracy: 0.8862 - val_se_out_accuracy: 0.8910\n",
      "Epoch 15/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2866 - original_out_loss: 0.1545 - se_out_loss: 0.1321 - original_out_accuracy: 0.9495 - se_out_accuracy: 0.9592\n",
      "Epoch 00015: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 226s 678ms/step - loss: 0.2868 - original_out_loss: 0.1544 - se_out_loss: 0.1324 - original_out_accuracy: 0.9496 - se_out_accuracy: 0.9590 - val_loss: 0.9240 - val_original_out_loss: 0.5605 - val_se_out_loss: 0.3635 - val_original_out_accuracy: 0.8814 - val_se_out_accuracy: 0.8850\n",
      "Epoch 16/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2391 - original_out_loss: 0.1226 - se_out_loss: 0.1165 - original_out_accuracy: 0.9587 - se_out_accuracy: 0.9635\n",
      "Epoch 00016: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 681ms/step - loss: 0.2397 - original_out_loss: 0.1226 - se_out_loss: 0.1171 - original_out_accuracy: 0.9587 - se_out_accuracy: 0.9632 - val_loss: 1.0138 - val_original_out_loss: 0.6196 - val_se_out_loss: 0.3943 - val_original_out_accuracy: 0.8862 - val_se_out_accuracy: 0.8862\n",
      "Epoch 17/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2343 - original_out_loss: 0.1185 - se_out_loss: 0.1158 - original_out_accuracy: 0.9628 - se_out_accuracy: 0.9647\n",
      "Epoch 00017: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 681ms/step - loss: 0.2340 - original_out_loss: 0.1182 - se_out_loss: 0.1157 - original_out_accuracy: 0.9629 - se_out_accuracy: 0.9648 - val_loss: 0.8797 - val_original_out_loss: 0.5281 - val_se_out_loss: 0.3516 - val_original_out_accuracy: 0.8862 - val_se_out_accuracy: 0.8850\n",
      "Epoch 18/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2417 - original_out_loss: 0.1247 - se_out_loss: 0.1169 - original_out_accuracy: 0.9604 - se_out_accuracy: 0.9653\n",
      "Epoch 00018: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 683ms/step - loss: 0.2421 - original_out_loss: 0.1251 - se_out_loss: 0.1170 - original_out_accuracy: 0.9603 - se_out_accuracy: 0.9653 - val_loss: 0.8557 - val_original_out_loss: 0.5040 - val_se_out_loss: 0.3517 - val_original_out_accuracy: 0.8814 - val_se_out_accuracy: 0.8874\n",
      "Epoch 19/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2082 - original_out_loss: 0.1070 - se_out_loss: 0.1011 - original_out_accuracy: 0.9680 - se_out_accuracy: 0.9698\n",
      "Epoch 00019: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 226s 678ms/step - loss: 0.2088 - original_out_loss: 0.1072 - se_out_loss: 0.1016 - original_out_accuracy: 0.9680 - se_out_accuracy: 0.9698 - val_loss: 0.9311 - val_original_out_loss: 0.5682 - val_se_out_loss: 0.3629 - val_original_out_accuracy: 0.8778 - val_se_out_accuracy: 0.8826\n",
      "Epoch 20/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.2012 - original_out_loss: 0.1110 - se_out_loss: 0.0903 - original_out_accuracy: 0.9634 - se_out_accuracy: 0.9710\n",
      "Epoch 00020: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 680ms/step - loss: 0.2010 - original_out_loss: 0.1109 - se_out_loss: 0.0902 - original_out_accuracy: 0.9633 - se_out_accuracy: 0.9711 - val_loss: 0.8890 - val_original_out_loss: 0.5462 - val_se_out_loss: 0.3429 - val_original_out_accuracy: 0.8886 - val_se_out_accuracy: 0.8934\n",
      "Epoch 21/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1782 - original_out_loss: 0.0926 - se_out_loss: 0.0855 - original_out_accuracy: 0.9706 - se_out_accuracy: 0.9736\n",
      "Epoch 00021: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 679ms/step - loss: 0.1778 - original_out_loss: 0.0924 - se_out_loss: 0.0854 - original_out_accuracy: 0.9707 - se_out_accuracy: 0.9737 - val_loss: 0.8595 - val_original_out_loss: 0.5253 - val_se_out_loss: 0.3342 - val_original_out_accuracy: 0.9006 - val_se_out_accuracy: 0.9114\n",
      "Epoch 22/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1800 - original_out_loss: 0.0917 - se_out_loss: 0.0883 - original_out_accuracy: 0.9692 - se_out_accuracy: 0.9742\n",
      "Epoch 00022: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 678ms/step - loss: 0.1795 - original_out_loss: 0.0914 - se_out_loss: 0.0881 - original_out_accuracy: 0.9693 - se_out_accuracy: 0.9743 - val_loss: 0.8886 - val_original_out_loss: 0.5426 - val_se_out_loss: 0.3461 - val_original_out_accuracy: 0.8910 - val_se_out_accuracy: 0.8922\n",
      "Epoch 23/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1650 - original_out_loss: 0.0813 - se_out_loss: 0.0837 - original_out_accuracy: 0.9754 - se_out_accuracy: 0.9745\n",
      "Epoch 00023: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 680ms/step - loss: 0.1647 - original_out_loss: 0.0811 - se_out_loss: 0.0835 - original_out_accuracy: 0.9753 - se_out_accuracy: 0.9746 - val_loss: 0.8691 - val_original_out_loss: 0.5227 - val_se_out_loss: 0.3465 - val_original_out_accuracy: 0.8934 - val_se_out_accuracy: 0.9018\n",
      "Epoch 24/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1653 - original_out_loss: 0.0885 - se_out_loss: 0.0768 - original_out_accuracy: 0.9712 - se_out_accuracy: 0.9775\n",
      "Epoch 00024: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 678ms/step - loss: 0.1658 - original_out_loss: 0.0890 - se_out_loss: 0.0768 - original_out_accuracy: 0.9711 - se_out_accuracy: 0.9774 - val_loss: 0.9392 - val_original_out_loss: 0.5686 - val_se_out_loss: 0.3706 - val_original_out_accuracy: 0.8838 - val_se_out_accuracy: 0.8934\n",
      "Epoch 25/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1469 - original_out_loss: 0.0770 - se_out_loss: 0.0699 - original_out_accuracy: 0.9749 - se_out_accuracy: 0.9800\n",
      "Epoch 00025: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 226s 676ms/step - loss: 0.1465 - original_out_loss: 0.0768 - se_out_loss: 0.0697 - original_out_accuracy: 0.9750 - se_out_accuracy: 0.9801 - val_loss: 0.9164 - val_original_out_loss: 0.5580 - val_se_out_loss: 0.3584 - val_original_out_accuracy: 0.8826 - val_se_out_accuracy: 0.9006\n",
      "Epoch 26/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1402 - original_out_loss: 0.0764 - se_out_loss: 0.0638 - original_out_accuracy: 0.9775 - se_out_accuracy: 0.9811\n",
      "Epoch 00026: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 681ms/step - loss: 0.1415 - original_out_loss: 0.0773 - se_out_loss: 0.0642 - original_out_accuracy: 0.9772 - se_out_accuracy: 0.9810 - val_loss: 0.8819 - val_original_out_loss: 0.5330 - val_se_out_loss: 0.3489 - val_original_out_accuracy: 0.8970 - val_se_out_accuracy: 0.8946\n",
      "Epoch 27/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1504 - original_out_loss: 0.0775 - se_out_loss: 0.0730 - original_out_accuracy: 0.9739 - se_out_accuracy: 0.9775\n",
      "Epoch 00027: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 684ms/step - loss: 0.1509 - original_out_loss: 0.0774 - se_out_loss: 0.0735 - original_out_accuracy: 0.9738 - se_out_accuracy: 0.9772 - val_loss: 0.9695 - val_original_out_loss: 0.5964 - val_se_out_loss: 0.3731 - val_original_out_accuracy: 0.8838 - val_se_out_accuracy: 0.8970\n",
      "Epoch 28/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1433 - original_out_loss: 0.0732 - se_out_loss: 0.0700 - original_out_accuracy: 0.9794 - se_out_accuracy: 0.9814\n",
      "Epoch 00028: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 683ms/step - loss: 0.1429 - original_out_loss: 0.0730 - se_out_loss: 0.0699 - original_out_accuracy: 0.9795 - se_out_accuracy: 0.9814 - val_loss: 0.8684 - val_original_out_loss: 0.5316 - val_se_out_loss: 0.3368 - val_original_out_accuracy: 0.8994 - val_se_out_accuracy: 0.9006\n",
      "Epoch 29/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1161 - original_out_loss: 0.0604 - se_out_loss: 0.0557 - original_out_accuracy: 0.9817 - se_out_accuracy: 0.9851\n",
      "Epoch 00029: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 221s 661ms/step - loss: 0.1173 - original_out_loss: 0.0616 - se_out_loss: 0.0557 - original_out_accuracy: 0.9816 - se_out_accuracy: 0.9852 - val_loss: 0.9191 - val_original_out_loss: 0.5603 - val_se_out_loss: 0.3588 - val_original_out_accuracy: 0.8874 - val_se_out_accuracy: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1301 - original_out_loss: 0.0700 - se_out_loss: 0.0601 - original_out_accuracy: 0.9788 - se_out_accuracy: 0.9832\n",
      "Epoch 00030: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 230s 689ms/step - loss: 0.1298 - original_out_loss: 0.0698 - se_out_loss: 0.0600 - original_out_accuracy: 0.9789 - se_out_accuracy: 0.9832 - val_loss: 0.9377 - val_original_out_loss: 0.5699 - val_se_out_loss: 0.3677 - val_original_out_accuracy: 0.8910 - val_se_out_accuracy: 0.8934\n",
      "Epoch 31/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1189 - original_out_loss: 0.0590 - se_out_loss: 0.0600 - original_out_accuracy: 0.9824 - se_out_accuracy: 0.9824\n",
      "Epoch 00031: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 680ms/step - loss: 0.1186 - original_out_loss: 0.0588 - se_out_loss: 0.0598 - original_out_accuracy: 0.9825 - se_out_accuracy: 0.9825 - val_loss: 0.9629 - val_original_out_loss: 0.5923 - val_se_out_loss: 0.3706 - val_original_out_accuracy: 0.8922 - val_se_out_accuracy: 0.8910\n",
      "Epoch 32/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1290 - original_out_loss: 0.0717 - se_out_loss: 0.0573 - original_out_accuracy: 0.9800 - se_out_accuracy: 0.9838\n",
      "Epoch 00032: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 680ms/step - loss: 0.1288 - original_out_loss: 0.0716 - se_out_loss: 0.0572 - original_out_accuracy: 0.9799 - se_out_accuracy: 0.9838 - val_loss: 0.9717 - val_original_out_loss: 0.6144 - val_se_out_loss: 0.3573 - val_original_out_accuracy: 0.8838 - val_se_out_accuracy: 0.9030\n",
      "Epoch 33/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1038 - original_out_loss: 0.0525 - se_out_loss: 0.0513 - original_out_accuracy: 0.9841 - se_out_accuracy: 0.9875\n",
      "Epoch 00033: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 683ms/step - loss: 0.1035 - original_out_loss: 0.0524 - se_out_loss: 0.0512 - original_out_accuracy: 0.9841 - se_out_accuracy: 0.9876 - val_loss: 0.8993 - val_original_out_loss: 0.5569 - val_se_out_loss: 0.3424 - val_original_out_accuracy: 0.9018 - val_se_out_accuracy: 0.9102\n",
      "Epoch 34/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1118 - original_out_loss: 0.0581 - se_out_loss: 0.0537 - original_out_accuracy: 0.9794 - se_out_accuracy: 0.9827\n",
      "Epoch 00034: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 683ms/step - loss: 0.1114 - original_out_loss: 0.0579 - se_out_loss: 0.0536 - original_out_accuracy: 0.9795 - se_out_accuracy: 0.9828 - val_loss: 0.9392 - val_original_out_loss: 0.5850 - val_se_out_loss: 0.3543 - val_original_out_accuracy: 0.8946 - val_se_out_accuracy: 0.9054\n",
      "Epoch 35/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.1101 - original_out_loss: 0.0568 - se_out_loss: 0.0533 - original_out_accuracy: 0.9800 - se_out_accuracy: 0.9850\n",
      "Epoch 00035: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 225s 674ms/step - loss: 0.1101 - original_out_loss: 0.0567 - se_out_loss: 0.0534 - original_out_accuracy: 0.9801 - se_out_accuracy: 0.9849 - val_loss: 0.9029 - val_original_out_loss: 0.5540 - val_se_out_loss: 0.3489 - val_original_out_accuracy: 0.9018 - val_se_out_accuracy: 0.9054\n",
      "Epoch 36/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0935 - original_out_loss: 0.0497 - se_out_loss: 0.0439 - original_out_accuracy: 0.9845 - se_out_accuracy: 0.9874\n",
      "Epoch 00036: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 228s 683ms/step - loss: 0.0935 - original_out_loss: 0.0497 - se_out_loss: 0.0438 - original_out_accuracy: 0.9844 - se_out_accuracy: 0.9874 - val_loss: 0.9884 - val_original_out_loss: 0.6142 - val_se_out_loss: 0.3742 - val_original_out_accuracy: 0.8850 - val_se_out_accuracy: 0.9030\n",
      "Epoch 37/100\n",
      "333/334 [============================>.] - ETA: 0s - loss: 0.0924 - original_out_loss: 0.0512 - se_out_loss: 0.0412 - original_out_accuracy: 0.9830 - se_out_accuracy: 0.9875\n",
      "Epoch 00037: val_loss did not improve from 0.81592\n",
      "334/334 [==============================] - 227s 681ms/step - loss: 0.0922 - original_out_loss: 0.0510 - se_out_loss: 0.0412 - original_out_accuracy: 0.9831 - se_out_accuracy: 0.9876 - val_loss: 0.8916 - val_original_out_loss: 0.5467 - val_se_out_loss: 0.3448 - val_original_out_accuracy: 0.9030 - val_se_out_accuracy: 0.9066\n",
      "Epoch 38/100\n",
      " 17/334 [>.............................] - ETA: 3:21 - loss: 0.0508 - original_out_loss: 0.0197 - se_out_loss: 0.0311 - original_out_accuracy: 0.9941 - se_out_accuracy: 0.9912"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-d0b300e6c33d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                                        )\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m           \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[0;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m   \u001b[0mshape_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m   \u001b[1;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m    503\u001b[0m   \"\"\"\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[1;34m(input, out_type, name)\u001b[0m\n\u001b[0;32m   9032\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   9033\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ShapeN\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9034\u001b[1;33m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[0;32m   9035\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9036\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=100,\n",
    "                                       callbacks=[tensorboard_callback, checkpointer],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('saved_models/weights.best.Xception_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.Xception_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 45s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_prediction(predictions, weights=[1.,1.]):\n",
    "    predictions = np.array(predictions)\n",
    "    weights = np.array(weights).reshape(predictions.shape[0], 1, 1)\n",
    "    return np.mean(np.multiply(pred, weights), axis=0)\n",
    "\n",
    "def cal_accuracy(predictions, truth):\n",
    "    if type(predictions) != list:\n",
    "        predictions = [predictions]\n",
    "    accuracy = []\n",
    "    for prediction in predictions:\n",
    "        prediction = np.argmax(prediction, axis=-1)\n",
    "        correct_nums = (prediction == truth).sum()\n",
    "        accuracy.append(correct_nums / len(prediction))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8971291866028708]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.Xception_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 48s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8911483253588517]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Time Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Augmentors\n",
    "tta_augmentors = [iaa.Fliplr(1.), iaa.Flipud(1.)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tta_test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=1, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'], tta_augmentors=tta_augmentors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836\r"
     ]
    }
   ],
   "source": [
    "all_predictions = np.zeros((df_test.shape[0], total_classes))\n",
    "count = 0\n",
    "total_len = len(tta_test_datagen)\n",
    "for images in tta_test_datagen:\n",
    "    count += 1\n",
    "    print(\"{}/{}\".format(count, total_len), end=\"\\r\")\n",
    "    preds = []\n",
    "    for image in images:\n",
    "        pred = model.predict_on_batch(image)\n",
    "        pred = combine_prediction(pred, [1.0, 1.0])\n",
    "        preds.append(pred)\n",
    "    all_predictions[count-1] = combine_prediction(preds, [1.0, 1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7894736842105263]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_accuracy(np.array(all_predictions).reshape((836, 133)), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - 10s 62ms/step\n"
     ]
    }
   ],
   "source": [
    "val_pred = model.predict_generator(generator=val_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n",
    "val_pred = combine_prediction(val_pred, [1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418/418 [==============================] - 24s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "test_datagen = MultiOutputDataGenerator(images_paths=df_test['img_path'].values, labels=df_test['label'].values,\n",
    "                              batch_size=2, image_dimensions=image_shape, shuffle=False,\n",
    "                              augmenter=None,\n",
    "                                preprocessor=preprocess_input,\n",
    "                            return_label=False, total_classes=total_classes, output_names=['original_out', 'se_out'])\n",
    "\n",
    "test_pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n",
    "\n",
    "test_pred = combine_prediction(test_pred, [1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(835, 133)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 133)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pseudolabels= np.argmax(val_pred, axis=-1)\n",
    "test_pseudolabels = np.argmax(test_pred, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(835,)\n",
      "(836,)\n"
     ]
    }
   ],
   "source": [
    "print(val_pseudolabels.shape)\n",
    "\n",
    "print(test_pseudolabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine pseudo labels with train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pseudo_data = pd.DataFrame({\"img_path\": np.concatenate([df_val['img_path'].values, df_test['img_path'].values]),\n",
    "                            \"label\": np.concatenate([val_pseudolabels, test_pseudolabels])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pseudo_train = pd.concat([pseudo_data, df_train], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8351, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pseudo_train_datagen = MultiOutputDataGenerator(images_paths=pseudo_train['img_path'].values, labels=pseudo_train['label'].values,\n",
    "                              batch_size=batch_size, image_dimensions=image_shape, shuffle=True,\n",
    "                              augmenter=create_augmenter(train=True), preprocessor=preprocess_input,\n",
    "                             return_label=True, total_classes=total_classes, output_names=['original_out', 'se_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception_PL.hdf5', \n",
    "                                  verbose=1, save_best_only=True)\n",
    "\n",
    "logdir = f\".\\logs\\pseudolabeling\"\n",
    "# Create target Directory if don't exist\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",\n",
    "                               mode=\"min\",\n",
    "                               patience=15,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.Xception_whole_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze pretrained part\n",
    "for layer in model.layers[:-15]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "sgd = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss={'original_out': 'categorical_crossentropy', 'se_out': 'categorical_crossentropy'},\n",
    "              loss_weights={'original_out': 1., 'se_out': 1.}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.7612 - original_out_loss: 1.4737 - se_out_loss: 1.2875 - original_out_accuracy: 0.8739 - se_out_accuracy: 0.8787\n",
      "Epoch 00001: val_loss improved from inf to 0.78541, saving model to saved_models/weights.best.Xception_PL.hdf5\n",
      "417/417 [==============================] - 279s 668ms/step - loss: 2.7618 - original_out_loss: 1.4742 - se_out_loss: 1.2876 - original_out_accuracy: 0.8737 - se_out_accuracy: 0.8784 - val_loss: 0.7854 - val_original_out_loss: 0.3316 - val_se_out_loss: 0.4538 - val_original_out_accuracy: 0.9018 - val_se_out_accuracy: 0.9102\n",
      "Epoch 2/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.3207 - original_out_loss: 1.1954 - se_out_loss: 1.1253 - original_out_accuracy: 0.8754 - se_out_accuracy: 0.8782\n",
      "Epoch 00002: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 668ms/step - loss: 2.3185 - original_out_loss: 1.1938 - se_out_loss: 1.1247 - original_out_accuracy: 0.8755 - se_out_accuracy: 0.8783 - val_loss: 0.9127 - val_original_out_loss: 0.3505 - val_se_out_loss: 0.5622 - val_original_out_accuracy: 0.9006 - val_se_out_accuracy: 0.9102\n",
      "Epoch 3/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.2447 - original_out_loss: 1.1529 - se_out_loss: 1.0918 - original_out_accuracy: 0.8761 - se_out_accuracy: 0.8813\n",
      "Epoch 00003: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 276s 661ms/step - loss: 2.2466 - original_out_loss: 1.1539 - se_out_loss: 1.0928 - original_out_accuracy: 0.8759 - se_out_accuracy: 0.8812 - val_loss: 0.9452 - val_original_out_loss: 0.3571 - val_se_out_loss: 0.5881 - val_original_out_accuracy: 0.9054 - val_se_out_accuracy: 0.9102\n",
      "Epoch 4/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.1911 - original_out_loss: 1.1275 - se_out_loss: 1.0636 - original_out_accuracy: 0.8748 - se_out_accuracy: 0.8788\n",
      "Epoch 00004: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 278s 666ms/step - loss: 2.1884 - original_out_loss: 1.1258 - se_out_loss: 1.0626 - original_out_accuracy: 0.8749 - se_out_accuracy: 0.8790 - val_loss: 1.0246 - val_original_out_loss: 0.3773 - val_se_out_loss: 0.6473 - val_original_out_accuracy: 0.9054 - val_se_out_accuracy: 0.9078\n",
      "Epoch 5/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.1449 - original_out_loss: 1.0888 - se_out_loss: 1.0561 - original_out_accuracy: 0.8787 - se_out_accuracy: 0.8781\n",
      "Epoch 00005: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 669ms/step - loss: 2.1409 - original_out_loss: 1.0864 - se_out_loss: 1.0545 - original_out_accuracy: 0.8790 - se_out_accuracy: 0.8784 - val_loss: 0.9943 - val_original_out_loss: 0.3758 - val_se_out_loss: 0.6185 - val_original_out_accuracy: 0.9030 - val_se_out_accuracy: 0.9078\n",
      "Epoch 6/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.1207 - original_out_loss: 1.0833 - se_out_loss: 1.0374 - original_out_accuracy: 0.8776 - se_out_accuracy: 0.8808\n",
      "Epoch 00006: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 669ms/step - loss: 2.1172 - original_out_loss: 1.0811 - se_out_loss: 1.0361 - original_out_accuracy: 0.8779 - se_out_accuracy: 0.8809 - val_loss: 1.0739 - val_original_out_loss: 0.3992 - val_se_out_loss: 0.6747 - val_original_out_accuracy: 0.8946 - val_se_out_accuracy: 0.9102\n",
      "Epoch 7/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.0608 - original_out_loss: 1.0501 - se_out_loss: 1.0108 - original_out_accuracy: 0.8799 - se_out_accuracy: 0.8815\n",
      "Epoch 00007: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 283s 680ms/step - loss: 2.0664 - original_out_loss: 1.0530 - se_out_loss: 1.0134 - original_out_accuracy: 0.8796 - se_out_accuracy: 0.8812 - val_loss: 1.0913 - val_original_out_loss: 0.4103 - val_se_out_loss: 0.6809 - val_original_out_accuracy: 0.8910 - val_se_out_accuracy: 0.9078\n",
      "Epoch 8/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 2.0331 - original_out_loss: 1.0309 - se_out_loss: 1.0022 - original_out_accuracy: 0.8808 - se_out_accuracy: 0.8822\n",
      "Epoch 00008: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 668ms/step - loss: 2.0291 - original_out_loss: 1.0287 - se_out_loss: 1.0004 - original_out_accuracy: 0.8809 - se_out_accuracy: 0.8825 - val_loss: 1.1249 - val_original_out_loss: 0.4258 - val_se_out_loss: 0.6991 - val_original_out_accuracy: 0.8922 - val_se_out_accuracy: 0.9018\n",
      "Epoch 9/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.9960 - original_out_loss: 1.0102 - se_out_loss: 0.9858 - original_out_accuracy: 0.8811 - se_out_accuracy: 0.8834\n",
      "Epoch 00009: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 668ms/step - loss: 1.9946 - original_out_loss: 1.0093 - se_out_loss: 0.9853 - original_out_accuracy: 0.8813 - se_out_accuracy: 0.8835 - val_loss: 1.1322 - val_original_out_loss: 0.4323 - val_se_out_loss: 0.6999 - val_original_out_accuracy: 0.8898 - val_se_out_accuracy: 0.9078\n",
      "Epoch 10/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.9488 - original_out_loss: 0.9848 - se_out_loss: 0.9640 - original_out_accuracy: 0.8819 - se_out_accuracy: 0.8816\n",
      "Epoch 00010: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 280s 671ms/step - loss: 1.9498 - original_out_loss: 0.9854 - se_out_loss: 0.9644 - original_out_accuracy: 0.8818 - se_out_accuracy: 0.8817 - val_loss: 1.1635 - val_original_out_loss: 0.4502 - val_se_out_loss: 0.7132 - val_original_out_accuracy: 0.8910 - val_se_out_accuracy: 0.9042\n",
      "Epoch 11/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.9247 - original_out_loss: 0.9691 - se_out_loss: 0.9556 - original_out_accuracy: 0.8809 - se_out_accuracy: 0.8847\n",
      "Epoch 00011: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 277s 665ms/step - loss: 1.9269 - original_out_loss: 0.9703 - se_out_loss: 0.9566 - original_out_accuracy: 0.8807 - se_out_accuracy: 0.8845 - val_loss: 1.2207 - val_original_out_loss: 0.4747 - val_se_out_loss: 0.7460 - val_original_out_accuracy: 0.8910 - val_se_out_accuracy: 0.8982\n",
      "Epoch 12/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.8970 - original_out_loss: 0.9486 - se_out_loss: 0.9484 - original_out_accuracy: 0.8810 - se_out_accuracy: 0.8837\n",
      "Epoch 00012: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 275s 659ms/step - loss: 1.8974 - original_out_loss: 0.9486 - se_out_loss: 0.9488 - original_out_accuracy: 0.8808 - se_out_accuracy: 0.8836 - val_loss: 1.2216 - val_original_out_loss: 0.4815 - val_se_out_loss: 0.7401 - val_original_out_accuracy: 0.8862 - val_se_out_accuracy: 0.8994\n",
      "Epoch 13/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.8578 - original_out_loss: 0.9317 - se_out_loss: 0.9261 - original_out_accuracy: 0.8826 - se_out_accuracy: 0.8853\n",
      "Epoch 00013: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 279s 668ms/step - loss: 1.8577 - original_out_loss: 0.9312 - se_out_loss: 0.9265 - original_out_accuracy: 0.8826 - se_out_accuracy: 0.8854 - val_loss: 1.2794 - val_original_out_loss: 0.5053 - val_se_out_loss: 0.7741 - val_original_out_accuracy: 0.8814 - val_se_out_accuracy: 0.8994\n",
      "Epoch 14/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.8329 - original_out_loss: 0.9142 - se_out_loss: 0.9187 - original_out_accuracy: 0.8851 - se_out_accuracy: 0.8862\n",
      "Epoch 00014: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 276s 663ms/step - loss: 1.8339 - original_out_loss: 0.9147 - se_out_loss: 0.9192 - original_out_accuracy: 0.8850 - se_out_accuracy: 0.8861 - val_loss: 1.3395 - val_original_out_loss: 0.5346 - val_se_out_loss: 0.8049 - val_original_out_accuracy: 0.8802 - val_se_out_accuracy: 0.8922\n",
      "Epoch 15/100\n",
      "416/417 [============================>.] - ETA: 0s - loss: 1.7898 - original_out_loss: 0.8952 - se_out_loss: 0.8945 - original_out_accuracy: 0.8853 - se_out_accuracy: 0.8863\n",
      "Epoch 00015: val_loss did not improve from 0.78541\n",
      "417/417 [==============================] - 280s 670ms/step - loss: 1.7900 - original_out_loss: 0.8954 - se_out_loss: 0.8946 - original_out_accuracy: 0.8853 - se_out_accuracy: 0.8862 - val_loss: 1.3769 - val_original_out_loss: 0.5563 - val_se_out_loss: 0.8207 - val_original_out_accuracy: 0.8743 - val_se_out_accuracy: 0.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "131/417 [========>.....................] - ETA: 3:08 - loss: 1.7145 - original_out_loss: 0.8450 - se_out_loss: 0.8695 - original_out_accuracy: 0.8893 - se_out_accuracy: 0.8916"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-f1000818e18b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                                        )\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m               training=training))\n\u001b[0m\u001b[0;32m    253\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fused_batch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    660\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvirtual_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;31m# Currently never reaches here since fused_batch_norm does not support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_fused_batch_norm\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    554\u001b[0m                                              momentum, inputs_size)\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance_update\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_update\u001b[1;34m(self, updates, inputs)\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1264\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1265\u001b[1;33m             \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1266\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36mmean_update\u001b[1;34m()\u001b[0m\n\u001b[0;32m    535\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mmean_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m         return self._assign_moving_average(self.moving_mean, mean, momentum,\n\u001b[1;32m--> 537\u001b[1;33m                                            inputs_size)\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mvariance_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\normalization.py\u001b[0m in \u001b[0;36m_assign_moving_average\u001b[1;34m(self, variable, value, momentum, inputs_size)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AssignMovingAvg'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m         \u001b[0mdecay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'decay'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdecay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m           \u001b[0mdecay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m   \u001b[1;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\henry\\anaconda3\\envs\\cuda10\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m  11070\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m  11071\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Sub\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 11072\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m  11073\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11074\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=pseudo_train_datagen,\n",
    "                                       validation_data=val_datagen,\n",
    "                                       epochs=100,\n",
    "                                       callbacks=[tensorboard_callback, early_stop, checkpointer, lr_scheduler],\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 48s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.895933014354067]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.Xception_PL.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 48s 57ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.90311004784689]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_generator(generator=test_datagen,\n",
    "                                       verbose=1,\n",
    "                                       )\n",
    "# Same weight\n",
    "cal_accuracy(combine_prediction(pred, [1., 1.]), df_test['label'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
